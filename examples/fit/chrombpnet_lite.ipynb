{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seqdata as sd\n",
    "import seqpro as sp\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tangermeme.predict import predict\n",
    "from bpnetlite.bpnet import BPNet, CountWrapper, ProfileWrapper, ControlWrapper, _ProfileLogitScaling\n",
    "from tangermeme.deep_lift_shap import deep_lift_shap, _nonlinear\n",
    "import modiscolite\n",
    "from modiscolite.util import calculate_window_offsets\n",
    "\n",
    "from eugene.utils import (\n",
    "    merge_parameters,\n",
    "    check_for_gpu,\n",
    ")\n",
    "from eugene.plot.performance import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = \"/cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/chrombpnet/K562_ATAC-seq_chrombpnet.yaml\"\n",
    "path_out = \"/cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/chrombpnet/fold_0/0.5\"\n",
    "overwrite = False\n",
    "os.makedirs(path_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'K562_ATAC-seq_chrombpnet_fold_0',\n",
       " 'threads': 4,\n",
       " 'random_state': 1234,\n",
       " 'seqdata': {'path': '/cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/prep_dataset/0.5/K562_ATAC-seq.minimal.seqdata',\n",
       "  'seq_var': 'seq',\n",
       "  'cov_var': 'cov',\n",
       "  'fold': 'fold_0',\n",
       "  'seq_length': 2114,\n",
       "  'target_length': 1000,\n",
       "  'max_jitter': 512,\n",
       "  'max_counts': 999999,\n",
       "  'min_counts': 0,\n",
       "  'outlier_threshold': 0.9999,\n",
       "  'neg_sampling_ratio': 0.1},\n",
       " 'model': {'n_filters': 512,\n",
       "  'n_layers': 8,\n",
       "  'n_outputs': 1,\n",
       "  'alpha': None,\n",
       "  'bias_model': '/cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/bias_model/fold_0/0.5/K562_ATAC-seq_bias_fold_0.torch'},\n",
       " 'training': {'learning_rate': 0.001,\n",
       "  'batch_size': 64,\n",
       "  'max_epochs': 50,\n",
       "  'validation_iter': 1000,\n",
       "  'rc_augment': True},\n",
       " 'evaluation': {'batch_size': 256},\n",
       " 'attribution': {'batch_size': 128, 'subsample': 30000, 'n_shuffles': 20},\n",
       " 'modisco': {'n_seqlets': 50000,\n",
       "  'window': 500,\n",
       "  'motif_db': '/cellar/users/aklie/projects/ML4GLand/tutorials/data/motifs.meme.txt'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = yaml.safe_load(open(path_params))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"seqdata\": {\n",
    "        \"ctrl_var\": None,\n",
    "        \"overwrite\": False,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"n_control_tracks\": None,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Parameters ---\n",
      "\tname: K562_ATAC-seq_chrombpnet_fold_0\n",
      "\tthreads: 4\n",
      "\trandom_state: 1234\n",
      "\tseqdata: \n",
      "\t\tpath: /cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/prep_dataset/0.5/K562_ATAC-seq.minimal.seqdata\n",
      "\t\tseq_var: seq\n",
      "\t\tcov_var: cov\n",
      "\t\tfold: fold_0\n",
      "\t\tseq_length: 2114\n",
      "\t\ttarget_length: 1000\n",
      "\t\tmax_jitter: 512\n",
      "\t\tmax_counts: 999999\n",
      "\t\tmin_counts: 0\n",
      "\t\toutlier_threshold: 0.9999\n",
      "\t\tneg_sampling_ratio: 0.1\n",
      "\t\tctrl_var: None\n",
      "\t\toverwrite: False\n",
      "\tmodel: \n",
      "\t\tn_filters: 512\n",
      "\t\tn_layers: 8\n",
      "\t\tn_outputs: 1\n",
      "\t\talpha: None\n",
      "\t\tbias_model: /cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/bias_model/fold_0/0.5/K562_ATAC-seq_bias_fold_0.torch\n",
      "\t\tn_control_tracks: None\n",
      "\ttraining: \n",
      "\t\tlearning_rate: 0.001\n",
      "\t\tbatch_size: 64\n",
      "\t\tmax_epochs: 50\n",
      "\t\tvalidation_iter: 1000\n",
      "\t\trc_augment: True\n",
      "\tevaluation: \n",
      "\t\tbatch_size: 256\n",
      "\tattribution: \n",
      "\t\tbatch_size: 128\n",
      "\t\tsubsample: 30000\n",
      "\t\tn_shuffles: 20\n",
      "\tmodisco: \n",
      "\t\tn_seqlets: 50000\n",
      "\t\twindow: 500\n",
      "\t\tmotif_db: /cellar/users/aklie/projects/ML4GLand/tutorials/data/motifs.meme.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merge with default parameters\n",
    "params = merge_parameters(path_params, default_params)\n",
    "\n",
    "# Log parameters\n",
    "message=(\"--- Parameters ---\\n\")\n",
    "for key, value in params.items():\n",
    "    message += f\"\\t{key}: \"\n",
    "    if isinstance(value, dict):\n",
    "        for key, value in value.items():\n",
    "            message += f\"\\n\\t\\t{key}: {value}\"\n",
    "        message += \"\\n\"\n",
    "    else:\n",
    "        message += f\"{value}\\n\"\n",
    "message += \"\\n\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab params\n",
    "name = params[\"name\"]\n",
    "threads = params[\"threads\"]\n",
    "random_state = params[\"random_state\"]\n",
    "\n",
    "# Check for GPU\n",
    "device = check_for_gpu()\n",
    "if device == torch.device(\"cpu\"):\n",
    "    raise ValueError(\"Cannot currently train bpnet-lite models on CPU. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading SeqData ---\n",
      "Reading sequence data from /cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/prep_dataset/0.5/K562_ATAC-seq.minimal.seqdata\n",
      "Sequence length is 2114\n",
      "Target length is 1000\n",
      "Trimming is 557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-------------- Load SeqData --------------#\n",
    "print(\"--- Loading SeqData ---\")\n",
    "path_seqdata = params[\"seqdata\"][\"path\"]\n",
    "seq_var = params[\"seqdata\"][\"seq_var\"]\n",
    "cov_var = params[\"seqdata\"][\"cov_var\"]\n",
    "ctrl_var = params[\"seqdata\"][\"ctrl_var\"]\n",
    "fold = params[\"seqdata\"][\"fold\"]\n",
    "seq_length = params[\"seqdata\"][\"seq_length\"]\n",
    "target_length = params[\"seqdata\"][\"target_length\"]\n",
    "max_jitter = params[\"seqdata\"][\"max_jitter\"]\n",
    "max_counts = params[\"seqdata\"][\"max_counts\"]\n",
    "min_counts = params[\"seqdata\"][\"min_counts\"]\n",
    "outlier_threshold = params[\"seqdata\"][\"outlier_threshold\"]\n",
    "\n",
    "# Load the data\n",
    "print(f\"Reading sequence data from {path_seqdata}\")\n",
    "sdata = sd.open_zarr(path_seqdata)\n",
    "\n",
    "# Define the trimming\n",
    "trimming = (seq_length - target_length) // 2\n",
    "seqs_start = (sdata.dims[\"_length\"] // 2) - (seq_length // 2)\n",
    "counts_start = (sdata.dims[\"_length\"] // 2) - (target_length // 2)\n",
    "print(f\"Sequence length is {seq_length}\")\n",
    "print(f\"Target length is {target_length}\")\n",
    "print(f\"Trimming is {trimming}\\n\")\n",
    "\n",
    "# Check if prefix.torch exists, if it does and overwrite is False, raise an error\n",
    "prefix = os.path.join(path_out, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/chrombpnet/fold_0/0.5/K562_ATAC-seq_chrombpnet_fold_0.torch already exists. Set overwrite=True to overwrite.\n",
      "Loading model from file, will only evaluate on test data.\n"
     ]
    }
   ],
   "source": [
    "generate = True\n",
    "if not overwrite and os.path.exists(prefix + \".torch\"):\n",
    "    print(f\"{prefix}.torch already exists. Set overwrite=True to overwrite.\")\n",
    "    generate = False\n",
    "    print(\"Loading model from file, will only evaluate on test data.\")\n",
    "if generate:\n",
    "    #-------------- Split the data --------------#\n",
    "    print(\"--- Splitting the data ---\")\n",
    "    training_idx = np.where(sdata[fold].isin([\"train\", \"valid\"]))[0]\n",
    "    training_data = sdata.isel(_sequence=training_idx)\n",
    "    print(f\"# training seqs: {training_data.dims['_sequence']}\")\n",
    "\n",
    "    # Sample neg_sampling_ratio negative sequences (type == \"negative\")\n",
    "    neg_sampling_ratio = params[\"seqdata\"][\"neg_sampling_ratio\"]\n",
    "    if neg_sampling_ratio is not None:\n",
    "        print(f\"Sampling {neg_sampling_ratio} negative sequences\")\n",
    "        neg_idx = np.where(sdata.type.values == \"negative\")[0]\n",
    "        loci_idx = np.where(sdata.type.values == \"loci\")[0]\n",
    "        neg_idx = np.random.choice(neg_idx, size=int(neg_sampling_ratio * len(loci_idx)), replace=False)\n",
    "        training_data = sdata.isel(_sequence=sorted(np.concatenate([loci_idx, neg_idx])))\n",
    "        print(f\"# training seqs after sampling negative sequences: {training_data.dims['_sequence']}\")\n",
    "    \n",
    "    # -------------- Filter the data --------------#\n",
    "    print(\"--- Filtering the data ---\")\n",
    "    print(f\"Filtering based on total counts between {min_counts} and {max_counts}\")\n",
    "    training_cov = training_data[cov_var].values\n",
    "    training_counts = training_cov[..., counts_start:counts_start + target_length].sum(axis=(1,2))\n",
    "    counts_msk = (training_counts <= max_counts) & (training_counts >= min_counts)\n",
    "    if outlier_threshold is not None:\n",
    "        print(f\"Further filtering based on outlier threshold of {outlier_threshold}\")\n",
    "        filt_counts = training_counts[counts_msk]\n",
    "        upper_thresh = np.quantile(filt_counts, outlier_threshold)\n",
    "        lower_thresh = np.quantile(filt_counts, 1 - outlier_threshold)\n",
    "        outlier_msk = (training_counts <= upper_thresh) & (training_counts >= lower_thresh)\n",
    "    else:\n",
    "        outlier_msk = counts_msk\n",
    "    training_data = training_data.isel(_sequence=outlier_msk)\n",
    "    print(f\"# training seqs after filtering: {training_data.dims['_sequence']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Instantiating a ChromBPNet model ---\n"
     ]
    }
   ],
   "source": [
    "#-------------- Instantiate the model --------------#\n",
    "print(\"--- Instantiating a ChromBPNet model ---\")\n",
    "n_filters = params[\"model\"][\"n_filters\"]\n",
    "n_layers = params[\"model\"][\"n_layers\"]\n",
    "n_outputs = 1\n",
    "n_control_tracks = 0 if params[\"model\"][\"n_control_tracks\"] is None else params[\"model\"][\"n_control_tracks\"]\n",
    "path_bias = params[\"model\"][\"bias_model\"]\n",
    "\n",
    "# Load the bias model\n",
    "bias_model = torch.load(path_bias, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing counts loss weight\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing counts loss weight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(\u001b[43mtraining_counts\u001b[49m[outlier_msk]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCounts loss weight is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# Get alpha\n",
    "alpha = params[\"model\"][\"alpha\"]\n",
    "if alpha is None:\n",
    "    print(\"Computing counts loss weight\")\n",
    "    alpha = np.median(training_counts[outlier_msk]) / 10\n",
    "    print(f\"Counts loss weight is {alpha}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessibility_model = BPNet(\n",
    "    n_filters=n_filters,\n",
    "    n_layers=n_layers,\n",
    "    n_outputs=n_outputs,\n",
    "    n_control_tracks=n_control_tracks,\n",
    "    trimming=trimming,\n",
    "    alpha=alpha,\n",
    "    name=prefix + \".accessibility\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpnetlite import ChromBPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromBPNet(\n",
      "  (bias): BPNet(\n",
      "    (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "    (irelu): ReLU()\n",
      "    (rconvs): ModuleList(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "      (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "      (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "    )\n",
      "    (rrelus): ModuleList(\n",
      "      (0-3): 4 x ReLU()\n",
      "    )\n",
      "    (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
      "    (linear): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (accessibility): BPNet(\n",
      "    (iconv): Conv1d(4, 512, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "    (irelu): ReLU()\n",
      "    (rconvs): ModuleList(\n",
      "      (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "      (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "      (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "      (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "      (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
      "      (5): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
      "      (6): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
      "      (7): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
      "    )\n",
      "    (rrelus): ModuleList(\n",
      "      (0-7): 8 x ReLU()\n",
      "    )\n",
      "    (fconv): Conv1d(512, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
      "    (linear): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (_log): _Log()\n",
      "  (_exp1): _Exp()\n",
      "  (_exp2): _Exp()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "arch = ChromBPNet(bias=bias_model, accessibility=accessibility_model, name=prefix)\n",
    "print(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training the model ---\n"
     ]
    }
   ],
   "source": [
    "#-------------- Train the model --------------#\n",
    "print(\"--- Training the model ---\")\n",
    "learning_rate = params[\"training\"][\"learning_rate\"]\n",
    "batch_size = params[\"training\"][\"batch_size\"]\n",
    "max_epochs = params[\"training\"][\"max_epochs\"]\n",
    "validation_iter = params[\"training\"][\"validation_iter\"]\n",
    "rc_augment = params[\"training\"][\"rc_augment\"]\n",
    "rng = np.random.default_rng(random_state)\n",
    "if ctrl_var is not None:\n",
    "    def transform(batch):\n",
    "        if max_jitter > 0:\n",
    "            batch[seq_var], batch[cov_var], batch[ctrl_var] = sp.jitter(batch[seq_var], batch[cov_var], batch[ctrl_var], max_jitter=max_jitter, length_axis=-1, jitter_axes=0)\n",
    "            batch[cov_var] = batch[cov_var][..., trimming:-trimming]\n",
    "            batch[ctrl_var] = batch[ctrl_var][..., trimming:-trimming]\n",
    "        else:\n",
    "            batch[seq_var] = batch[seq_var][..., seqs_start:seqs_start + seq_length]\n",
    "            batch[cov_var] = batch[cov_var][..., counts_start:counts_start + target_length]\n",
    "            batch[ctrl_var] = batch[ctrl_var][..., counts_start:counts_start + target_length]\n",
    "        batch[seq_var] = sp.DNA.ohe(batch[seq_var]).transpose(0, 2, 1)\n",
    "        if rc_augment and rng.choice(2) == 1:\n",
    "            batch[seq_var] = sp.reverse_complement(batch[seq_var], alphabet=sp.DNA, length_axis=-1, ohe_axis=1).copy()\n",
    "            batch[cov_var] = np.flip(batch[cov_var], axis=-1).copy()\n",
    "            batch[ctrl_var] = np.flip(batch[ctrl_var], axis=-1).copy()\n",
    "        return batch\n",
    "else:\n",
    "    def transform(batch):\n",
    "        if max_jitter > 0:\n",
    "            batch[seq_var], batch[cov_var] = sp.jitter(batch[seq_var], batch[cov_var], max_jitter=max_jitter, length_axis=-1, jitter_axes=0)  # jitter\n",
    "            batch[cov_var] = batch[cov_var][..., trimming:-trimming]  # trim\n",
    "        else:\n",
    "            batch[seq_var] = batch[seq_var][..., seqs_start:seqs_start + seq_length]\n",
    "            batch[cov_var] = batch[cov_var][..., counts_start:counts_start + target_length]\n",
    "        batch[seq_var] = sp.DNA.ohe(batch[seq_var]).transpose(0, 2, 1)  # one hot encode\n",
    "        if rc_augment and rng.choice(2) == 1:\n",
    "            batch[seq_var] = sp.reverse_complement(batch[seq_var], alphabet=sp.DNA, length_axis=-1, ohe_axis=1).copy()\n",
    "            batch[cov_var] = np.flip(batch[cov_var], axis=-1).copy()\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the train dataloader with variables: ['seq', 'cov']\n",
      "Dataloader contains 3225 batches\n"
     ]
    }
   ],
   "source": [
    "# Get the train dataloader\n",
    "vars = [seq_var, cov_var] if ctrl_var is None else [seq_var, cov_var, ctrl_var]\n",
    "print(f\"Creating the train dataloader with variables: {vars}\")\n",
    "train_idx = np.where(training_data[fold] == \"train\")[0]\n",
    "train_data = training_data.isel(_sequence=train_idx).load()\n",
    "train_dl = sd.get_torch_dataloader(\n",
    "    train_data,\n",
    "    sample_dims=['_sequence'],\n",
    "    variables=vars,\n",
    "    prefetch_factor=None,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    return_tuples=True\n",
    ")\n",
    "print(f\"Dataloader contains {len(train_dl)} batches\")\n",
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch looks like: torch.Size([64, 4, 2114]), torch.Size([64, 1, 1000])\n",
      "Validation data shapes: torch.Size([19758, 4, 2114]), torch.Size([19758, 1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Get the validation data\n",
    "valid_idx = np.where(training_data[fold] == \"valid\")[0]\n",
    "valid_data = training_data.isel(_sequence=valid_idx)\n",
    "if ctrl_var is None:\n",
    "    print(f\"Batch looks like: {batch[0].shape}, {batch[1].shape}\")\n",
    "    X_ctl_valid = None\n",
    "else:\n",
    "    print(f\"Batch looks like: {batch[0].shape}, {batch[1].shape}, {batch[2].shape}\")\n",
    "    X_ctl_valid = torch.tensor(valid_data[ctrl_var].values[..., counts_start:counts_start + target_length], dtype=torch.float32)\n",
    "X_valid = torch.tensor(sp.ohe(valid_data[seq_var].values[:, seqs_start:seqs_start + seq_length], alphabet=sp.DNA).transpose(0, 2, 1), dtype=torch.float32)\n",
    "y_valid = torch.tensor(valid_data[cov_var].values[..., counts_start:counts_start + target_length], dtype=torch.float32)\n",
    "print(f\"Validation data shapes: {X_valid.shape}, {y_valid.shape}\")\n",
    "if X_ctl_valid is not None:\n",
    "    print(f\"Validation control data shape: {X_ctl_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the GPU and prepare the optimizer\n",
    "arch.cuda()\n",
    "optimizer = torch.optim.Adam(arch.parameters(), lr=learning_rate)\n",
    "print(f\"Optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n",
      "Epoch\tIteration\tTraining Time\tValidation Time\tTraining MNLL\tTraining Count MSE\tValidation MNLL\tValidation Profile Correlation\tValidation Count Pearson\tValidation Count MSE\tSaved?\n",
      "0\t0\t0.0784\t19.9469\t1102.8982\t8.1176\t1461.2247\t0.5814768\t-0.49701312\t2432.7896\tTrue\n",
      "0\t100\t19.4687\t19.6798\t1232.3691\t8.73\t1180.0857\t0.67765784\t0.16837353\t8.589\tTrue\n",
      "0\t200\t19.4912\t19.7019\t1113.8108\t8.3522\t1185.489\t0.6750057\t0.16823225\t8.5883\tFalse\n",
      "0\t300\t19.4881\t19.7033\t1060.8896\t8.0917\t1171.6475\t0.6775518\t0.16790468\t8.5862\tTrue\n",
      "0\t400\t19.4859\t19.6994\t1245.4434\t8.9466\t1167.8865\t0.6805395\t0.16635057\t8.5765\tTrue\n",
      "0\t500\t19.4944\t19.7062\t1212.5472\t1.3094\t1172.0259\t0.6777533\t0.53520316\t1.962\tTrue\n",
      "0\t600\t19.4882\t19.6998\t1310.5752\t1.2685\t1203.8654\t0.6718181\t0.55039525\t1.7129\tFalse\n",
      "0\t700\t19.4822\t19.6945\t979.5961\t1.5919\t1156.2998\t0.68392307\t0.5303401\t1.8876\tTrue\n",
      "0\t800\t19.4631\t19.687\t987.5355\t1.6372\t1155.8967\t0.6834537\t0.55007964\t1.6132\tTrue\n",
      "0\t900\t19.475\t19.6839\t1039.1317\t2.1396\t1170.4404\t0.682307\t0.54989505\t1.6241\tFalse\n",
      "0\t1000\t19.4535\t19.6912\t1257.6812\t1.7275\t1142.3473\t0.6899687\t0.55425984\t1.601\tTrue\n",
      "0\t1100\t19.4572\t19.6641\t1231.772\t1.3186\t1167.9672\t0.67825234\t0.5562651\t1.4448\tFalse\n",
      "0\t1200\t19.4397\t19.6488\t1113.6487\t1.8348\t1140.6482\t0.6907984\t0.55639225\t1.4641\tTrue\n",
      "0\t1300\t19.4419\t19.6497\t1230.3929\t1.8495\t1175.11\t0.67971075\t0.5653813\t1.632\tFalse\n",
      "3\t1500\t19.3004\t19.4198\t893.588\t1.2583\t961.2452\t0.7688902\t0.73028594\t0.9494\tFalse\n",
      "3\t1800\t19.2915\t19.4232\t906.6483\t0.6474\t964.3431\t0.7691845\t0.74161947\t0.9217\tFalse\n",
      "3\t1900\t19.2859\t19.4191\t812.5801\t1.2882\t966.2913\t0.7690004\t0.7290353\t1.2446\tFalse\n",
      "3\t2000\t19.2948\t19.4424\t982.1086\t0.963\t960.5107\t0.76797915\t0.7396761\t0.8969\tTrue\n",
      "3\t2100\t19.3061\t19.4198\t1113.0754\t0.8658\t960.4199\t0.7684468\t0.7425062\t0.9276\tFalse\n",
      "3\t2200\t19.294\t19.4203\t952.9445\t0.9557\t957.075\t0.7707076\t0.74172264\t0.8962\tTrue\n",
      "3\t2300\t19.2895\t19.4202\t917.6287\t0.5429\t959.6518\t0.7696556\t0.7447018\t0.879\tFalse\n",
      "3\t2400\t19.2948\t19.4224\t1019.816\t0.7984\t955.3001\t0.7698894\t0.742874\t0.8856\tTrue\n",
      "3\t2500\t19.2904\t19.4363\t940.5844\t0.7105\t957.1378\t0.7703931\t0.7426725\t0.9099\tFalse\n",
      "3\t2600\t19.2876\t19.422\t950.4053\t0.9745\t957.3703\t0.7699184\t0.74480987\t0.8839\tFalse\n",
      "3\t2700\t19.2931\t19.4208\t821.4707\t1.033\t955.4358\t0.77052015\t0.7449655\t0.9843\tFalse\n",
      "3\t2800\t19.293\t19.4178\t837.8884\t1.2237\t959.8493\t0.76767606\t0.74612486\t0.8744\tFalse\n",
      "3\t2900\t19.289\t19.4194\t1096.7808\t0.8917\t957.347\t0.7706422\t0.7454256\t0.9403\tFalse\n",
      "3\t3000\t19.2939\t19.4228\t1037.9829\t0.6776\t957.9925\t0.7682805\t0.7450206\t1.0127\tFalse\n",
      "3\t3100\t19.2856\t19.4153\t924.2688\t0.8517\t953.4378\t0.77051353\t0.7412074\t0.9314\tFalse\n",
      "3\t3200\t19.2925\t19.4366\t810.9631\t2.0018\t955.2217\t0.7698246\t0.7445085\t0.9566\tFalse\n",
      "4\t0\t4.5611\t19.4391\t967.213\t0.8339\t953.9693\t0.77104837\t0.7463803\t0.8779\tTrue\n",
      "4\t100\t19.2802\t19.4217\t872.679\t0.7328\t964.6927\t0.7688477\t0.74513435\t0.8793\tFalse\n",
      "4\t200\t19.2806\t19.4164\t664.182\t2.42\t951.4827\t0.77197105\t0.7466663\t0.8757\tTrue\n",
      "4\t300\t19.2869\t19.4164\t854.7023\t1.3579\t957.0933\t0.7699817\t0.7484984\t0.8683\tFalse\n",
      "4\t400\t19.2913\t19.4155\t748.2917\t0.9631\t954.5558\t0.7709782\t0.7467103\t0.9911\tFalse\n",
      "4\t500\t19.2923\t19.4172\t787.9389\t1.1312\t955.1144\t0.77094764\t0.74615693\t0.9291\tFalse\n",
      "4\t600\t19.2859\t19.4174\t940.6042\t1.1223\t956.9191\t0.7696719\t0.74387544\t0.9652\tFalse\n",
      "4\t700\t19.2943\t19.4117\t983.6139\t0.598\t950.5852\t0.77142894\t0.7456963\t0.9448\tFalse\n",
      "4\t800\t19.2906\t19.4373\t975.3986\t0.6768\t955.8416\t0.77011377\t0.7486611\t0.9409\tFalse\n",
      "4\t900\t19.292\t19.4162\t1035.847\t0.8124\t952.569\t0.77141374\t0.7475291\t0.9181\tFalse\n",
      "4\t1000\t19.292\t19.4189\t982.0425\t0.8196\t956.3348\t0.7711919\t0.74698305\t0.9139\tFalse\n",
      "4\t1100\t19.2889\t19.4194\t881.1608\t0.8429\t956.9494\t0.77001077\t0.7477309\t0.9178\tFalse\n",
      "4\t1200\t19.2901\t19.4186\t925.3271\t1.0714\t956.4771\t0.7711233\t0.74540687\t0.9011\tFalse\n",
      "4\t1300\t19.2923\t19.4203\t856.1438\t1.0298\t955.1727\t0.7706285\t0.7496785\t0.8931\tFalse\n",
      "4\t1400\t19.2865\t19.4167\t938.0837\t1.0563\t960.332\t0.7709532\t0.7443765\t0.8944\tFalse\n",
      "4\t1500\t19.3014\t19.4438\t971.6761\t0.8138\t954.2915\t0.77252734\t0.7463172\t0.8907\tFalse\n",
      "4\t1600\t19.2914\t19.4211\t1177.5785\t1.2935\t950.6303\t0.77162266\t0.74786454\t0.8806\tTrue\n",
      "4\t1700\t19.2969\t19.4188\t881.8176\t1.0481\t951.3102\t0.77168816\t0.7517876\t0.8863\tFalse\n",
      "4\t1800\t19.2999\t19.4157\t1020.4845\t0.7417\t954.7725\t0.7724512\t0.7478254\t0.8697\tFalse\n",
      "4\t1900\t19.2958\t19.4353\t963.9651\t1.002\t954.515\t0.77064764\t0.7524737\t0.8672\tFalse\n",
      "4\t2000\t19.2919\t19.4177\t999.2327\t0.8197\t949.3981\t0.7729325\t0.751428\t0.8659\tTrue\n",
      "4\t2100\t19.3036\t19.4164\t889.1865\t0.5395\t952.2037\t0.7711152\t0.74927264\t0.9691\tFalse\n",
      "4\t2200\t19.2855\t19.42\t873.4202\t0.8645\t954.6999\t0.7720937\t0.7511783\t0.8648\tFalse\n",
      "4\t2300\t19.288\t19.4319\t762.0718\t1.0926\t956.329\t0.77256685\t0.7530893\t0.861\tFalse\n",
      "4\t2400\t19.293\t19.4167\t868.3842\t0.5602\t954.198\t0.7729849\t0.75419086\t0.934\tFalse\n",
      "4\t2500\t19.2923\t19.4155\t1007.8539\t0.7627\t952.3141\t0.7703903\t0.75105244\t0.8626\tFalse\n",
      "4\t2600\t19.2897\t19.4138\t917.9656\t1.0232\t950.7503\t0.7723693\t0.75353473\t1.0004\tFalse\n",
      "4\t2700\t19.2824\t19.4117\t848.5748\t1.2073\t947.5562\t0.7741517\t0.75205743\t0.8844\tTrue\n",
      "4\t2800\t19.2851\t19.4108\t922.0441\t0.57\t961.1229\t0.7722261\t0.7499035\t0.9068\tFalse\n",
      "4\t2900\t19.2811\t19.4108\t948.5798\t1.0085\t950.0051\t0.77362347\t0.7535566\t0.8571\tFalse\n",
      "4\t3000\t19.2876\t19.4103\t917.5572\t0.611\t956.019\t0.773746\t0.7559248\t0.9983\tFalse\n",
      "4\t3100\t19.2922\t19.4119\t842.3064\t0.5481\t962.3637\t0.77071136\t0.7545186\t0.8639\tFalse\n",
      "4\t3200\t19.2965\t19.4081\t885.0959\t0.6753\t950.4147\t0.77266467\t0.7517138\t0.9265\tFalse\n",
      "5\t0\t4.5608\t19.4158\t754.8926\t1.4521\t950.6537\t0.77373505\t0.75009966\t0.9267\tFalse\n",
      "5\t100\t19.2839\t19.4125\t926.4634\t0.7104\t953.7325\t0.7727068\t0.7509475\t0.8612\tFalse\n",
      "5\t200\t19.2892\t19.4116\t865.2152\t0.6581\t956.2493\t0.7724261\t0.7526143\t0.8705\tFalse\n",
      "5\t300\t19.2811\t19.4134\t948.8042\t1.153\t952.3029\t0.77273345\t0.75040096\t0.8752\tFalse\n",
      "5\t400\t19.2812\t19.4126\t877.0601\t1.0757\t948.7792\t0.77395475\t0.75238854\t0.8986\tFalse\n",
      "5\t500\t19.2865\t19.434\t760.7172\t1.2822\t948.5569\t0.7729426\t0.75328445\t0.9091\tFalse\n",
      "5\t600\t19.2811\t19.4129\t833.509\t0.4692\t950.6489\t0.7733499\t0.7566459\t0.8459\tTrue\n",
      "5\t700\t19.2907\t19.4151\t708.5087\t1.1576\t947.4957\t0.77320856\t0.7559743\t0.8467\tTrue\n",
      "5\t800\t19.2815\t19.4136\t874.2191\t0.8789\t951.1852\t0.7742116\t0.75317717\t0.8742\tFalse\n",
      "5\t900\t19.291\t19.4129\t890.4103\t0.8055\t950.0359\t0.7728166\t0.753909\t0.8651\tFalse\n",
      "5\t1000\t19.2837\t19.4087\t869.5154\t0.9346\t949.06\t0.772167\t0.7550985\t0.8487\tFalse\n",
      "5\t1100\t19.2791\t19.4076\t912.0793\t1.0908\t949.3431\t0.7724448\t0.7548576\t0.8541\tFalse\n",
      "5\t1200\t19.2885\t19.4119\t784.4597\t0.833\t956.5411\t0.77215374\t0.7560465\t0.8482\tFalse\n",
      "5\t1300\t19.2827\t19.4132\t922.254\t0.8734\t945.1053\t0.7745664\t0.75881976\t0.858\tTrue\n",
      "5\t1400\t19.2937\t19.4093\t1033.6389\t1.5289\t952.6215\t0.77351296\t0.75444394\t1.0105\tFalse\n",
      "5\t1500\t19.2912\t19.4086\t925.7736\t0.78\t952.2284\t0.77259415\t0.7517512\t0.8763\tFalse\n",
      "5\t1600\t19.2903\t19.413\t862.2294\t0.8065\t948.7783\t0.7747551\t0.75661224\t0.8555\tFalse\n",
      "5\t1700\t19.3013\t19.4103\t1009.2732\t0.5778\t950.9426\t0.771332\t0.75760025\t0.9645\tFalse\n",
      "5\t1800\t19.2913\t19.4093\t1032.1393\t0.6401\t951.4398\t0.77359015\t0.75862\t0.9458\tFalse\n",
      "5\t1900\t19.2827\t19.4127\t859.6474\t0.5381\t950.2463\t0.7720379\t0.75721514\t0.885\tFalse\n",
      "5\t2000\t19.2924\t19.4104\t763.0489\t1.2458\t956.5608\t0.7727898\t0.7537372\t0.9154\tFalse\n",
      "5\t2100\t19.2907\t19.4126\t810.3894\t1.9674\t945.7885\t0.7745311\t0.75957805\t0.8576\tFalse\n",
      "5\t2200\t19.3002\t19.416\t873.6014\t0.5803\t947.214\t0.7735974\t0.75805753\t0.8444\tFalse\n",
      "5\t2300\t19.2968\t19.4285\t776.4776\t1.321\t953.5986\t0.77329123\t0.76006216\t0.8326\tFalse\n",
      "5\t2400\t19.2892\t19.4108\t855.0168\t0.5882\t948.6776\t0.77228075\t0.75859606\t0.9392\tFalse\n",
      "5\t2500\t19.2962\t19.4084\t918.571\t0.7521\t947.2264\t0.7727937\t0.7605877\t0.9085\tFalse\n",
      "5\t2600\t19.2931\t19.4121\t862.783\t0.6249\t948.5621\t0.77496547\t0.7597724\t0.86\tFalse\n",
      "5\t2700\t19.2912\t19.4128\t944.2341\t0.4582\t951.5096\t0.77195054\t0.75816023\t0.844\tFalse\n",
      "5\t2800\t19.29\t19.4098\t922.8628\t0.7784\t948.1623\t0.773487\t0.7578077\t0.9553\tFalse\n",
      "5\t2900\t19.2888\t19.4086\t909.1055\t1.073\t945.733\t0.77494353\t0.756519\t0.8585\tFalse\n",
      "5\t3000\t19.2884\t19.4266\t906.1174\t0.8757\t949.1349\t0.77371377\t0.75862134\t0.9064\tFalse\n",
      "5\t3100\t19.2929\t19.4118\t1022.5606\t0.8897\t952.4698\t0.77321965\t0.7581191\t0.9523\tFalse\n",
      "5\t3200\t19.2871\t19.4068\t927.4591\t1.1014\t948.4258\t0.7739716\t0.75784165\t0.8428\tFalse\n",
      "6\t0\t4.5597\t19.404\t879.3325\t1.0227\t950.0672\t0.77368045\t0.75687575\t0.8526\tFalse\n",
      "6\t100\t19.2928\t19.4225\t966.5747\t0.9119\t955.0554\t0.77409697\t0.75716877\t0.8974\tFalse\n",
      "6\t200\t19.2915\t19.4067\t850.717\t0.7715\t950.36\t0.77460074\t0.7550579\t0.8549\tFalse\n",
      "6\t300\t19.2836\t19.4142\t856.8945\t0.7488\t948.62\t0.7740333\t0.75721544\t0.8481\tFalse\n",
      "6\t400\t19.2919\t19.4143\t902.1596\t0.5464\t951.3235\t0.7738839\t0.7566924\t0.9257\tFalse\n",
      "6\t500\t19.2944\t19.4127\t812.3754\t0.5263\t948.7185\t0.7741043\t0.76030755\t0.9417\tFalse\n",
      "6\t600\t19.284\t19.4087\t714.042\t1.7589\t949.2254\t0.7742037\t0.7580366\t0.944\tFalse\n",
      "6\t700\t19.2926\t19.4078\t826.0491\t1.627\t948.8282\t0.7746305\t0.7510488\t0.9198\tFalse\n",
      "6\t800\t19.2821\t19.427\t769.9572\t0.847\t944.2384\t0.77552754\t0.7607972\t0.9102\tFalse\n",
      "6\t900\t19.2802\t19.4115\t1049.418\t0.6822\t946.5208\t0.77387065\t0.76224524\t0.8413\tFalse\n",
      "6\t1000\t19.2949\t19.4137\t814.2494\t1.0918\t945.5626\t0.7738344\t0.7585655\t0.8727\tFalse\n",
      "6\t1100\t19.29\t19.4131\t925.1454\t0.6914\t948.4761\t0.773513\t0.7595322\t0.934\tFalse\n",
      "6\t1200\t19.299\t19.4119\t778.5342\t0.7688\t947.6163\t0.7752495\t0.757213\t0.8585\tFalse\n",
      "6\t1300\t19.2958\t19.4115\t842.1622\t0.7661\t944.8161\t0.7749087\t0.7622212\t0.8822\tFalse\n",
      "6\t1400\t19.2929\t19.4146\t946.5884\t0.6643\t947.0486\t0.77402216\t0.760417\t0.8325\tTrue\n",
      "6\t1500\t19.2938\t19.4091\t1095.6892\t0.7475\t953.4926\t0.77362674\t0.76175517\t0.8507\tFalse\n",
      "6\t1600\t19.2968\t19.4137\t929.5286\t0.7904\t949.0651\t0.7750999\t0.7610258\t0.8405\tFalse\n",
      "6\t1700\t19.3022\t19.4101\t909.0638\t0.8347\t945.2786\t0.77613175\t0.76334816\t0.8553\tFalse\n",
      "6\t1800\t19.2941\t19.4099\t852.5521\t1.2359\t946.4524\t0.7755665\t0.7614348\t0.8336\tTrue\n",
      "6\t1900\t19.2889\t19.422\t949.8715\t0.8709\t945.2494\t0.7750777\t0.7623251\t0.8286\tTrue\n",
      "6\t2000\t19.2947\t19.4067\t823.7095\t0.7581\t946.8478\t0.7748129\t0.7621412\t0.881\tFalse\n",
      "6\t2100\t19.2926\t19.4104\t998.4442\t0.7924\t946.381\t0.7746889\t0.7622823\t0.8325\tFalse\n",
      "6\t2200\t19.2879\t19.408\t964.3181\t0.8758\t949.426\t0.77323836\t0.760393\t0.8725\tFalse\n",
      "6\t2300\t19.2866\t19.4285\t911.8699\t0.7249\t951.8009\t0.77352536\t0.7609378\t0.858\tFalse\n",
      "6\t2400\t19.2843\t19.4077\t701.6035\t1.0557\t953.8192\t0.7742151\t0.76173824\t0.8524\tFalse\n",
      "6\t2500\t19.2799\t19.4048\t839.0608\t0.6329\t949.6226\t0.7743419\t0.7626943\t0.8307\tFalse\n",
      "6\t2600\t19.2918\t19.4174\t860.2571\t0.8345\t944.8327\t0.7752355\t0.7634958\t0.8887\tFalse\n",
      "6\t2700\t19.2988\t19.4058\t880.5511\t1.1129\t944.2504\t0.77548105\t0.7617305\t0.862\tFalse\n",
      "6\t2800\t19.2944\t19.4063\t998.0573\t0.5519\t947.765\t0.77506876\t0.76396\t0.8634\tFalse\n",
      "6\t2900\t19.2879\t19.4078\t861.4016\t0.6721\t949.8804\t0.77502155\t0.7618962\t0.8367\tFalse\n",
      "6\t3000\t19.2937\t19.4146\t843.3704\t0.7471\t951.774\t0.77290595\t0.76339895\t0.8573\tFalse\n",
      "6\t3100\t19.2964\t19.4118\t892.0316\t0.5653\t948.3302\t0.77636176\t0.7583362\t0.9221\tFalse\n",
      "6\t3200\t19.2912\t19.4104\t839.8245\t0.8522\t951.0718\t0.77582747\t0.7560615\t0.9151\tFalse\n",
      "7\t0\t4.5617\t19.4159\t897.2197\t0.9115\t948.1913\t0.77456504\t0.75817835\t0.8569\tFalse\n",
      "7\t100\t19.3085\t19.429\t752.1968\t1.1125\t956.5381\t0.7746233\t0.7607312\t0.9671\tFalse\n",
      "7\t200\t19.2907\t19.4117\t1017.1662\t1.1\t946.491\t0.7752678\t0.76462483\t0.8196\tFalse\n",
      "7\t300\t19.3017\t19.4116\t765.8785\t0.7969\t941.4673\t0.7760525\t0.7635877\t0.866\tTrue\n",
      "7\t400\t19.2948\t19.4123\t805.0848\t0.6287\t946.1768\t0.77522004\t0.76267165\t0.8281\tFalse\n",
      "7\t500\t19.293\t19.4126\t802.8378\t0.8064\t948.9014\t0.77498925\t0.7619439\t0.8813\tFalse\n",
      "7\t600\t19.2977\t19.4127\t943.9371\t0.8286\t948.2968\t0.77390337\t0.7619263\t0.8303\tFalse\n",
      "7\t700\t19.3003\t19.4114\t859.1007\t1.4007\t946.3236\t0.77531123\t0.756731\t0.9319\tFalse\n",
      "7\t800\t19.2906\t19.414\t860.1753\t0.5607\t955.7047\t0.772999\t0.75343335\t0.9202\tFalse\n",
      "7\t900\t19.2922\t19.429\t847.4063\t0.8331\t945.5186\t0.7749503\t0.75836176\t0.9213\tFalse\n",
      "7\t1000\t19.2907\t19.412\t974.1332\t0.5699\t946.167\t0.77597034\t0.7621552\t0.8282\tFalse\n",
      "7\t1100\t19.2991\t19.4088\t841.8604\t1.3646\t944.2224\t0.77673197\t0.7605481\t0.8441\tFalse\n",
      "7\t1200\t19.2916\t19.4068\t713.5701\t0.6725\t943.9068\t0.7747337\t0.7636127\t0.8345\tTrue\n",
      "7\t1300\t19.2967\t19.4077\t814.4969\t0.7066\t942.757\t0.77583766\t0.75589925\t1.0612\tFalse\n",
      "7\t1400\t19.2921\t19.4071\t864.8542\t0.8216\t944.3285\t0.77481383\t0.7626417\t0.8951\tFalse\n",
      "7\t1500\t19.2924\t19.4103\t922.9987\t0.8245\t943.2649\t0.77582633\t0.7626731\t0.9553\tFalse\n",
      "7\t1600\t19.2848\t19.4052\t793.4868\t0.7438\t942.0782\t0.77601993\t0.76035434\t0.857\tTrue\n",
      "7\t1700\t19.2852\t19.4262\t781.5028\t0.729\t950.4822\t0.7743377\t0.757007\t0.8415\tFalse\n",
      "7\t1800\t19.2952\t19.4081\t857.5134\t0.5238\t944.9851\t0.7756637\t0.7601862\t0.8401\tFalse\n",
      "7\t1900\t19.2971\t19.4072\t914.2954\t0.6878\t946.448\t0.77410406\t0.7592839\t0.8864\tFalse\n",
      "7\t2000\t19.2878\t19.5853\t844.9162\t0.9363\t953.8638\t0.7749353\t0.7605726\t0.8399\tFalse\n",
      "7\t2100\t19.2882\t19.4288\t947.4883\t0.5114\t944.7812\t0.7758531\t0.7605126\t0.8339\tFalse\n",
      "7\t2200\t19.2896\t19.4057\t952.7917\t0.6604\t942.1385\t0.7757735\t0.7596608\t0.8433\tTrue\n",
      "7\t2300\t19.2898\t19.4056\t900.4094\t0.5679\t945.8936\t0.77543694\t0.76361203\t0.8804\tFalse\n",
      "7\t2400\t19.2823\t19.4032\t793.5208\t0.4801\t945.8938\t0.77611685\t0.75948966\t0.8651\tFalse\n",
      "7\t2500\t19.2926\t19.4222\t902.4626\t0.8133\t949.5092\t0.77475315\t0.75952464\t0.8363\tFalse\n",
      "7\t2600\t19.2807\t19.4055\t892.4669\t0.6188\t944.9598\t0.77525294\t0.7644203\t0.8226\tFalse\n",
      "7\t2700\t19.2838\t19.4092\t829.9386\t0.8344\t944.5314\t0.7766338\t0.7589522\t0.8521\tFalse\n",
      "7\t2800\t19.2822\t19.4233\t800.4448\t0.5595\t945.83\t0.7753475\t0.76005423\t0.8345\tFalse\n",
      "7\t2900\t19.2928\t19.4042\t833.6221\t1.0533\t945.3268\t0.7752009\t0.75586814\t0.9116\tFalse\n",
      "7\t3000\t19.2836\t19.3969\t937.5454\t0.5309\t944.4397\t0.77586126\t0.7595223\t0.8836\tFalse\n",
      "7\t3100\t19.2793\t19.4027\t839.1466\t0.713\t943.3342\t0.7768971\t0.7606093\t0.8959\tFalse\n",
      "7\t3200\t19.2796\t19.4001\t863.2339\t0.8701\t951.7827\t0.77396613\t0.7613408\t0.8395\tFalse\n",
      "8\t0\t4.5591\t19.4028\t909.0776\t0.5428\t949.811\t0.7738691\t0.7577889\t0.8504\tFalse\n",
      "8\t100\t19.2854\t19.4039\t752.6253\t0.6713\t947.9875\t0.7766886\t0.7621536\t0.8313\tFalse\n",
      "8\t200\t19.2898\t19.4021\t958.9028\t0.6267\t947.4204\t0.7759875\t0.7571491\t0.8473\tFalse\n",
      "8\t300\t19.2957\t19.409\t897.8735\t0.4907\t945.9734\t0.7755682\t0.75982374\t0.9269\tFalse\n",
      "8\t400\t19.2851\t19.3999\t934.3887\t0.6933\t943.9802\t0.7759688\t0.7614802\t0.8348\tFalse\n",
      "8\t500\t19.2814\t19.406\t869.467\t1.0217\t945.881\t0.77516556\t0.76047117\t0.8355\tFalse\n",
      "8\t600\t19.2803\t19.3998\t875.1167\t0.7037\t945.5789\t0.7764918\t0.7594433\t0.9053\tFalse\n",
      "8\t700\t19.2892\t19.4005\t911.9791\t0.5026\t945.5479\t0.77495015\t0.7582166\t0.8437\tFalse\n",
      "8\t800\t19.2878\t19.4017\t813.083\t0.4964\t946.27\t0.776231\t0.76060724\t0.8939\tFalse\n",
      "8\t900\t19.2818\t19.4228\t955.4857\t0.7813\t947.0266\t0.7761419\t0.7608502\t0.8544\tFalse\n",
      "8\t1000\t19.2765\t19.4012\t774.2582\t1.3687\t956.05\t0.77437574\t0.7541639\t0.9951\tFalse\n",
      "8\t1100\t19.2877\t19.4016\t907.0573\t0.8863\t952.4863\t0.7751265\t0.76078886\t0.8588\tFalse\n",
      "8\t1200\t19.28\t19.415\t768.4126\t1.2766\t945.6548\t0.77659744\t0.7593701\t0.8473\tFalse\n",
      "8\t1300\t19.2769\t19.4013\t878.6118\t0.435\t953.5734\t0.7737328\t0.7608393\t0.8309\tFalse\n",
      "8\t1400\t19.2805\t19.4013\t825.3651\t0.7879\t953.747\t0.77479297\t0.75646716\t0.8664\tFalse\n",
      "8\t1500\t19.2804\t19.4037\t856.539\t0.5957\t946.3881\t0.7753474\t0.76295567\t0.8584\tFalse\n",
      "8\t1600\t19.2889\t19.4092\t981.0462\t0.442\t944.3188\t0.7754876\t0.76073056\t0.9087\tFalse\n",
      "8\t1700\t19.2993\t19.4077\t953.3734\t0.6768\t950.1368\t0.77461535\t0.76155514\t0.8332\tFalse\n",
      "8\t1800\t19.2819\t19.4018\t895.7069\t0.7664\t946.3077\t0.7768776\t0.7609392\t0.866\tFalse\n",
      "8\t1900\t19.2746\t19.4059\t821.7633\t0.5882\t945.178\t0.77629465\t0.76288617\t0.8414\tFalse\n",
      "8\t2000\t19.2909\t19.4019\t843.8768\t0.9872\t952.5958\t0.7757187\t0.755191\t0.8602\tFalse\n",
      "8\t2100\t19.2874\t19.4035\t831.1907\t0.6122\t946.7116\t0.77686304\t0.75676286\t1.057\tFalse\n",
      "8\t2200\t19.284\t19.4289\t919.6757\t1.0899\t947.7144\t0.77419674\t0.7621777\t0.8266\tFalse\n",
      "8\t2300\t19.2849\t19.4039\t927.37\t0.5789\t941.4727\t0.7766704\t0.7592065\t0.8396\tTrue\n",
      "8\t2400\t19.282\t19.4037\t798.327\t0.5097\t948.0082\t0.77559674\t0.76213974\t0.8272\tFalse\n",
      "8\t2500\t19.2794\t19.4011\t917.9619\t0.9326\t942.3016\t0.77702326\t0.76260173\t0.8293\tFalse\n",
      "8\t2600\t19.2773\t19.4046\t836.6359\t0.7978\t942.9829\t0.7763875\t0.76322067\t0.9568\tFalse\n",
      "8\t2700\t19.2833\t19.4\t825.9598\t0.8667\t946.7111\t0.7755502\t0.7611079\t0.873\tFalse\n",
      "8\t2800\t19.2855\t19.4024\t871.0267\t1.8056\t945.7993\t0.7761896\t0.7610117\t0.8324\tFalse\n",
      "8\t2900\t19.2799\t19.4055\t1004.2054\t0.6797\t946.5694\t0.77590305\t0.7604336\t0.8415\tFalse\n",
      "8\t3000\t19.2912\t19.4064\t746.5303\t0.5544\t944.7743\t0.77562237\t0.7609114\t0.9533\tFalse\n",
      "8\t3100\t19.289\t19.4068\t743.0889\t0.6347\t945.1855\t0.77682084\t0.76014745\t0.8563\tFalse\n",
      "8\t3200\t19.2792\t19.4228\t959.0012\t0.658\t945.2938\t0.7762426\t0.7617985\t0.8409\tFalse\n",
      "9\t0\t4.5612\t19.4297\t853.7883\t0.6143\t942.3029\t0.7768869\t0.76108915\t0.8431\tFalse\n",
      "9\t100\t19.2874\t19.4014\t710.3752\t1.0002\t942.7473\t0.77592283\t0.75608337\t0.8909\tFalse\n",
      "9\t200\t19.2895\t19.4065\t977.6736\t0.6125\t944.3572\t0.7770988\t0.7543236\t0.8939\tFalse\n",
      "9\t300\t19.2927\t19.4003\t831.448\t1.025\t942.7983\t0.776806\t0.7635029\t0.8712\tFalse\n",
      "9\t400\t19.2864\t19.4053\t821.0502\t0.6044\t943.0634\t0.7760999\t0.76170415\t0.9252\tFalse\n",
      "9\t500\t19.2959\t19.4054\t864.6907\t0.5936\t941.8023\t0.7776795\t0.7604583\t0.8337\tTrue\n",
      "9\t600\t19.2807\t19.4068\t801.8708\t0.4059\t947.7731\t0.77645296\t0.7581137\t0.9422\tFalse\n",
      "9\t700\t19.2967\t19.4247\t837.0402\t0.4597\t945.0435\t0.7755873\t0.7598006\t0.8473\tFalse\n",
      "9\t800\t19.2938\t19.4078\t728.2081\t0.4924\t945.886\t0.77684057\t0.7584766\t0.8429\tFalse\n",
      "9\t900\t19.2852\t19.403\t1048.7517\t0.5828\t947.8151\t0.77632624\t0.75769985\t0.8487\tFalse\n",
      "9\t1000\t19.2834\t19.4048\t751.6112\t1.2948\t943.3326\t0.7770969\t0.7597979\t0.834\tFalse\n",
      "9\t1100\t19.2917\t19.4044\t851.6009\t0.4866\t952.6116\t0.77352506\t0.76162857\t0.8655\tFalse\n",
      "9\t1200\t19.2874\t19.4036\t789.7784\t1.131\t945.0567\t0.77741605\t0.7576862\t0.9163\tFalse\n",
      "9\t1300\t19.2926\t19.4042\t804.0984\t1.0846\t946.8047\t0.77683306\t0.7583365\t0.8589\tFalse\n",
      "9\t1400\t19.2878\t19.4006\t866.4211\t0.6472\t947.3342\t0.7766976\t0.7572309\t0.8409\tFalse\n",
      "9\t1500\t19.2869\t19.4053\t834.3951\t0.4258\t944.5778\t0.775533\t0.7614431\t0.8726\tFalse\n",
      "9\t1600\t19.2901\t19.4084\t883.9284\t0.6386\t943.9391\t0.77602404\t0.76014346\t0.8439\tFalse\n",
      "9\t1700\t19.2926\t19.419\t927.8005\t0.9949\t943.2776\t0.7768132\t0.7590904\t0.8643\tFalse\n",
      "9\t1800\t19.2864\t19.4009\t892.6005\t0.3669\t946.9108\t0.77686167\t0.76160586\t0.8378\tFalse\n",
      "9\t1900\t19.2918\t19.3998\t786.6786\t1.0131\t944.2333\t0.77677006\t0.7617132\t0.8276\tFalse\n",
      "9\t2000\t19.2901\t19.416\t770.7029\t0.6785\t943.7391\t0.77681047\t0.7559608\t0.8708\tFalse\n",
      "9\t2100\t19.2836\t19.4018\t992.8318\t0.5215\t945.3502\t0.7765584\t0.7623237\t0.8517\tFalse\n",
      "9\t2200\t19.2857\t19.406\t758.0375\t0.6027\t945.3384\t0.7769337\t0.7607922\t0.8423\tFalse\n",
      "9\t2300\t19.2895\t19.4015\t865.3315\t0.7923\t943.2225\t0.7765948\t0.7571932\t0.9107\tFalse\n",
      "9\t2400\t19.2855\t19.4031\t809.4685\t0.425\t945.6589\t0.77521336\t0.7602701\t0.8386\tFalse\n",
      "9\t2500\t19.2879\t19.3997\t911.2656\t0.8285\t949.6315\t0.77551794\t0.7608894\t0.8428\tFalse\n",
      "9\t2600\t19.2905\t19.4007\t792.4368\t0.8434\t950.5515\t0.77674717\t0.75770617\t0.9345\tFalse\n",
      "9\t2700\t19.293\t19.3999\t836.3591\t0.6784\t947.6724\t0.7753021\t0.75386584\t0.8994\tFalse\n",
      "9\t2800\t19.2841\t19.4063\t817.5076\t0.4212\t945.2653\t0.775952\t0.75415933\t0.8622\tFalse\n",
      "9\t2900\t19.2871\t19.4011\t758.9919\t0.7527\t951.1488\t0.77636594\t0.75889534\t0.839\tFalse\n",
      "9\t3000\t19.2881\t19.4248\t837.2078\t0.5913\t945.4352\t0.77582633\t0.76103574\t0.835\tFalse\n",
      "9\t3100\t19.288\t19.4077\t845.9376\t0.6693\t945.8675\t0.7757217\t0.75603116\t0.9489\tFalse\n",
      "9\t3200\t19.2982\t19.4088\t853.8504\t0.8007\t947.5863\t0.77685416\t0.7620362\t0.8287\tFalse\n",
      "10\t0\t4.5629\t19.4104\t894.6723\t0.4865\t946.1759\t0.7759826\t0.75382936\t0.9191\tFalse\n",
      "10\t100\t19.3001\t19.4119\t823.3508\t0.6035\t946.889\t0.77619374\t0.7592575\t0.8394\tFalse\n",
      "10\t200\t19.313\t19.4112\t836.1385\t0.7051\t952.2322\t0.7746977\t0.759165\t0.8498\tFalse\n",
      "10\t300\t19.3103\t19.4121\t808.0091\t0.6453\t945.0455\t0.7769056\t0.7543923\t0.8617\tFalse\n",
      "10\t400\t19.2925\t19.4131\t890.0946\t0.7416\t943.9426\t0.7759379\t0.757236\t0.8478\tFalse\n",
      "18\t100\t19.2747\t19.3948\t754.2085\t0.5162\t948.5873\t0.7754361\t0.7451029\t0.9143\tFalse\n",
      "18\t200\t19.2747\t19.3919\t761.1132\t0.5107\t951.2003\t0.7752321\t0.7396208\t0.9902\tFalse\n",
      "18\t300\t19.271\t19.4209\t808.1028\t0.2664\t947.0498\t0.77572554\t0.7447148\t0.9767\tFalse\n",
      "18\t400\t19.2777\t19.39\t914.8812\t0.8433\t945.5534\t0.77533054\t0.7414501\t0.9395\tFalse\n",
      "18\t500\t19.2771\t19.3889\t1074.6646\t0.2793\t944.2808\t0.77603847\t0.74197495\t0.9501\tFalse\n",
      "18\t600\t19.2748\t19.3898\t750.3639\t0.3572\t959.0793\t0.77308995\t0.74215645\t0.9136\tFalse\n",
      "18\t700\t19.2819\t19.3917\t764.5796\t0.5562\t946.1879\t0.7761341\t0.74136996\t0.9371\tFalse\n",
      "18\t800\t19.2752\t19.3907\t824.2019\t0.3654\t948.3611\t0.7746152\t0.7439847\t0.9151\tFalse\n",
      "18\t900\t19.2696\t19.3897\t752.1306\t0.752\t948.9193\t0.7748831\t0.74339294\t0.9043\tFalse\n",
      "18\t1000\t19.2629\t19.3969\t728.3416\t0.4334\t945.5159\t0.775536\t0.73742586\t0.9018\tFalse\n",
      "18\t1100\t19.276\t19.3876\t704.2571\t0.4154\t948.2183\t0.7762936\t0.7401122\t0.8964\tFalse\n",
      "18\t1200\t19.2771\t19.3977\t804.9396\t0.4066\t951.735\t0.7753613\t0.73604774\t0.9097\tFalse\n",
      "18\t1300\t19.2725\t19.3904\t760.924\t0.3489\t946.5719\t0.7752956\t0.7453646\t0.9033\tFalse\n",
      "18\t1400\t19.2733\t19.3905\t897.395\t0.3713\t946.6548\t0.775803\t0.7384287\t0.9117\tFalse\n",
      "18\t1500\t19.2738\t19.3928\t951.6129\t0.5465\t946.1205\t0.7763398\t0.7376893\t0.9383\tFalse\n",
      "18\t1600\t19.2703\t19.3912\t859.2916\t0.2526\t950.6332\t0.77589536\t0.7434107\t0.9693\tFalse\n",
      "18\t1700\t19.2724\t19.3922\t883.043\t0.5262\t944.2992\t0.77687144\t0.7445975\t0.8969\tFalse\n",
      "18\t1800\t19.2836\t19.3911\t825.6355\t0.266\t944.9124\t0.77615947\t0.74275434\t0.9016\tFalse\n",
      "18\t1900\t19.2778\t19.3925\t955.4726\t0.4526\t944.8574\t0.77707666\t0.74287415\t0.9417\tFalse\n",
      "18\t2000\t19.2769\t19.3907\t853.8707\t0.4974\t944.4948\t0.7767569\t0.74438864\t0.9241\tFalse\n",
      "18\t2100\t19.273\t19.3893\t834.4559\t0.2651\t945.5933\t0.77621156\t0.7415124\t0.8971\tFalse\n",
      "18\t2200\t19.2816\t19.3905\t877.6646\t0.7054\t947.4874\t0.77663654\t0.7431441\t0.9274\tFalse\n",
      "18\t2300\t19.2657\t19.3885\t978.8257\t0.6398\t945.1259\t0.776351\t0.74505717\t0.9377\tFalse\n",
      "18\t2400\t19.2631\t19.4057\t866.8868\t0.5293\t946.109\t0.77533126\t0.7449237\t0.8807\tFalse\n",
      "18\t2500\t19.2786\t19.3916\t737.0557\t0.3044\t948.5242\t0.77504665\t0.74203813\t1.0218\tFalse\n",
      "18\t2600\t19.3025\t19.381\t727.5513\t0.2842\t946.437\t0.775764\t0.7389429\t0.9591\tFalse\n",
      "18\t2700\t19.2695\t19.3754\t739.5383\t0.3963\t944.9786\t0.7766064\t0.7420362\t0.9316\tFalse\n",
      "18\t2800\t19.2561\t19.3798\t727.7844\t0.3095\t945.7448\t0.77577585\t0.7406313\t0.9118\tFalse\n",
      "18\t2900\t19.2658\t19.3902\t891.0552\t0.4559\t950.1624\t0.77556384\t0.73575014\t0.9359\tFalse\n",
      "18\t3000\t19.2673\t19.411\t924.4989\t0.3985\t944.7802\t0.7763536\t0.74290466\t0.8987\tFalse\n",
      "18\t3100\t19.2731\t19.3947\t734.1325\t0.3442\t948.8699\t0.77575916\t0.74155384\t0.9317\tFalse\n",
      "18\t3200\t19.2675\t19.3888\t813.7357\t0.3814\t944.9459\t0.77656054\t0.7451623\t0.8778\tFalse\n",
      "19\t0\t4.566\t19.3936\t828.4448\t0.3257\t949.0908\t0.7752343\t0.7445481\t1.0223\tFalse\n",
      "19\t100\t19.2658\t19.4092\t829.1898\t0.4902\t953.1967\t0.7752716\t0.7374308\t0.9168\tFalse\n",
      "19\t200\t19.2724\t19.3897\t759.9445\t0.4118\t949.4749\t0.7754962\t0.7359404\t0.92\tFalse\n",
      "19\t300\t19.2725\t19.3878\t822.0496\t0.3398\t944.3611\t0.77582467\t0.7381128\t0.926\tFalse\n",
      "19\t400\t19.2707\t19.4063\t951.5399\t0.2962\t946.0932\t0.7755248\t0.7402332\t0.9559\tFalse\n",
      "19\t500\t19.2671\t19.3923\t962.4326\t0.2795\t945.4269\t0.7755874\t0.7350689\t0.9845\tFalse\n",
      "19\t600\t19.2711\t19.39\t888.2875\t0.3742\t944.1796\t0.77581334\t0.7443701\t0.8869\tFalse\n",
      "19\t700\t19.2713\t19.4101\t904.6915\t0.6377\t952.7545\t0.77632326\t0.7351938\t0.9132\tFalse\n",
      "19\t800\t19.2658\t19.3873\t930.0339\t0.2635\t947.3442\t0.77519554\t0.7449479\t0.9421\tFalse\n",
      "19\t900\t19.2618\t19.385\t761.2655\t0.6903\t950.3486\t0.77580285\t0.741841\t0.8983\tFalse\n",
      "19\t1000\t19.2733\t19.408\t877.2715\t0.3945\t948.1116\t0.77552915\t0.7393117\t0.974\tFalse\n",
      "19\t1100\t19.2716\t19.3863\t843.4146\t0.3391\t951.364\t0.77535796\t0.73104995\t0.9715\tFalse\n",
      "19\t1200\t19.2712\t19.391\t740.6454\t0.3755\t949.7397\t0.77581567\t0.7413881\t0.9361\tFalse\n",
      "19\t1300\t19.2775\t19.4105\t842.6653\t0.3209\t953.7281\t0.7744087\t0.74369144\t0.9199\tFalse\n",
      "19\t1400\t19.2707\t19.3923\t771.7102\t0.5569\t948.3288\t0.77583367\t0.7441843\t0.9118\tFalse\n",
      "19\t1500\t19.2815\t19.3869\t785.6844\t0.3108\t949.7777\t0.77571476\t0.7428443\t0.9013\tFalse\n",
      "19\t1600\t19.2727\t19.4109\t737.5878\t0.3972\t946.6649\t0.77573\t0.74651855\t0.8767\tFalse\n",
      "19\t1700\t19.2803\t19.3878\t981.2328\t0.4711\t947.7802\t0.77542144\t0.74376076\t0.9295\tFalse\n",
      "19\t1800\t19.2784\t19.3878\t921.7657\t0.4473\t946.0502\t0.7756775\t0.7372131\t0.9529\tFalse\n",
      "19\t1900\t19.2687\t19.4026\t831.3845\t0.5516\t952.301\t0.774835\t0.73722816\t0.9204\tFalse\n",
      "19\t2000\t19.2715\t19.387\t811.0736\t0.3246\t945.3471\t0.7755134\t0.74476814\t0.9148\tFalse\n",
      "19\t2100\t19.2785\t19.3904\t769.0082\t0.5452\t951.1835\t0.7758534\t0.7402855\t0.946\tFalse\n",
      "19\t2200\t19.2808\t19.4076\t860.6326\t0.3955\t949.8878\t0.7751779\t0.7390846\t0.9304\tFalse\n",
      "19\t2300\t19.2692\t19.3967\t729.4048\t0.328\t946.8282\t0.7755588\t0.73710126\t0.9057\tFalse\n",
      "19\t2400\t19.274\t19.3945\t755.5718\t0.9365\t947.9939\t0.77557015\t0.7398468\t0.8939\tFalse\n",
      "19\t2500\t19.2774\t19.4129\t903.5853\t0.5232\t945.6125\t0.77546805\t0.73917043\t0.9277\tFalse\n",
      "19\t2600\t19.2894\t19.395\t771.5453\t0.5243\t951.3019\t0.77425444\t0.73739594\t0.9314\tFalse\n",
      "19\t2700\t19.2856\t19.3914\t1016.2589\t0.2924\t948.4607\t0.7762784\t0.73341346\t1.0411\tFalse\n",
      "19\t2800\t19.2762\t19.3941\t808.8986\t0.591\t949.4625\t0.7757441\t0.7395442\t0.9498\tFalse\n",
      "19\t2900\t19.2662\t19.3873\t842.5806\t0.296\t946.8875\t0.7750175\t0.73949105\t0.9282\tFalse\n",
      "19\t3000\t19.2621\t19.389\t826.6981\t0.334\t948.1211\t0.7756312\t0.739733\t0.9086\tFalse\n",
      "19\t3100\t19.2747\t19.3894\t869.9869\t0.29\t948.2524\t0.77575976\t0.73752964\t0.9431\tFalse\n",
      "19\t3200\t19.2777\t19.3926\t703.8389\t0.3283\t951.669\t0.77507114\t0.7417975\t0.8961\tFalse\n",
      "20\t0\t4.5587\t19.3925\t824.3772\t0.2321\t950.9997\t0.77567065\t0.7398808\t0.9035\tFalse\n",
      "20\t100\t19.2674\t19.3902\t845.1113\t0.6473\t954.7835\t0.7752583\t0.7391364\t0.9232\tFalse\n",
      "20\t200\t19.2803\t19.4125\t826.8002\t0.3152\t951.7238\t0.77536964\t0.74090254\t0.896\tFalse\n",
      "20\t300\t19.2783\t19.3914\t883.0479\t0.3536\t949.0222\t0.7755941\t0.734818\t0.9373\tFalse\n",
      "20\t400\t19.2759\t19.4026\t860.3739\t0.2504\t947.3811\t0.77561015\t0.7373085\t0.9257\tFalse\n",
      "20\t500\t19.2803\t19.3962\t918.3226\t0.4015\t950.6025\t0.77516305\t0.7375354\t0.9308\tFalse\n",
      "20\t600\t19.2873\t19.3943\t892.3428\t0.3517\t945.6841\t0.77585185\t0.737334\t0.9072\tFalse\n",
      "20\t700\t19.2756\t19.3971\t847.899\t0.2121\t957.1804\t0.77440923\t0.73918617\t0.9067\tFalse\n",
      "20\t800\t19.2873\t19.3969\t898.8209\t0.4802\t944.8633\t0.77594274\t0.740799\t0.9235\tFalse\n",
      "20\t900\t19.2748\t19.3954\t813.6663\t0.3816\t948.0195\t0.77572346\t0.74046546\t0.8964\tFalse\n",
      "20\t1000\t19.2736\t19.4005\t715.5801\t0.3854\t949.4623\t0.7750596\t0.73973054\t0.9173\tFalse\n",
      "20\t1100\t19.2831\t19.3893\t838.7698\t0.404\t950.4921\t0.77614903\t0.74290407\t0.8889\tFalse\n",
      "20\t1200\t19.2776\t19.392\t744.291\t0.3935\t950.4503\t0.7757856\t0.73861676\t0.9272\tFalse\n",
      "20\t1300\t19.2855\t19.3933\t815.5189\t0.3977\t947.5106\t0.7762025\t0.74261856\t0.8945\tFalse\n",
      "20\t1400\t19.2718\t19.392\t860.9425\t0.3053\t949.3896\t0.77484083\t0.74336326\t0.897\tFalse\n",
      "20\t1500\t19.2861\t19.3913\t983.1764\t0.2414\t946.1812\t0.7754258\t0.7413703\t0.8952\tFalse\n",
      "20\t1600\t19.2831\t19.3937\t831.5623\t0.262\t947.1479\t0.7754026\t0.74026513\t0.9773\tFalse\n",
      "20\t1700\t19.2736\t19.3942\t904.9003\t0.413\t947.6111\t0.7759149\t0.735117\t0.9433\tFalse\n",
      "20\t1800\t19.2699\t19.396\t753.6909\t0.3379\t949.1908\t0.77516\t0.7343917\t0.9621\tFalse\n",
      "20\t1900\t19.2706\t19.3904\t818.8639\t0.4524\t947.5299\t0.7758487\t0.7367921\t0.9242\tFalse\n",
      "20\t2000\t19.279\t19.3955\t884.6511\t0.3881\t949.2465\t0.77403146\t0.7413635\t0.9287\tFalse\n",
      "20\t2100\t19.2749\t19.3954\t834.4301\t0.2375\t949.5084\t0.7753826\t0.74571085\t0.9412\tFalse\n",
      "20\t2200\t19.279\t19.3946\t734.4805\t0.7285\t948.9257\t0.7749604\t0.7404914\t0.9134\tFalse\n",
      "20\t2300\t19.2738\t19.3924\t929.0242\t0.3428\t949.3407\t0.7750752\t0.74088854\t0.892\tFalse\n",
      "20\t2400\t19.2772\t19.3935\t926.1618\t0.4267\t950.7424\t0.77566856\t0.7408613\t0.9154\tFalse\n",
      "20\t2500\t19.2714\t19.3925\t860.2579\t0.3797\t945.8704\t0.7755833\t0.7420387\t0.9012\tFalse\n",
      "20\t2600\t19.2704\t19.3927\t836.2379\t0.4097\t952.1063\t0.7754518\t0.73791486\t1.0092\tFalse\n",
      "20\t2700\t19.2712\t19.3985\t846.8249\t1.0887\t951.0588\t0.774397\t0.7463953\t0.8843\tFalse\n",
      "20\t2800\t19.2817\t19.3986\t794.811\t0.4801\t949.3774\t0.7753199\t0.73922545\t0.9188\tFalse\n",
      "20\t2900\t19.2824\t19.3995\t777.6691\t0.4837\t948.9317\t0.77569383\t0.7391587\t0.9341\tFalse\n",
      "20\t3000\t19.2881\t19.4025\t691.207\t0.7733\t949.0474\t0.7759544\t0.74268866\t0.9087\tFalse\n",
      "20\t3100\t19.277\t19.3965\t900.6649\t0.2371\t946.0163\t0.775916\t0.7441234\t0.8877\tFalse\n",
      "20\t3200\t19.284\t19.4017\t929.6097\t0.5189\t949.8018\t0.7757183\t0.73901486\t1.1357\tFalse\n",
      "21\t0\t4.557\t19.3893\t831.3346\t0.2489\t947.3602\t0.7752193\t0.7391525\t0.9141\tFalse\n",
      "21\t100\t19.2783\t19.393\t957.2587\t0.3002\t950.2115\t0.7759546\t0.73983705\t0.9376\tFalse\n",
      "21\t200\t19.2795\t19.3891\t726.0348\t0.348\t946.4213\t0.7759761\t0.74399346\t0.8902\tFalse\n",
      "21\t300\t19.278\t19.3932\t875.3951\t0.5227\t945.0052\t0.7757355\t0.74597937\t0.8797\tFalse\n",
      "21\t400\t19.2759\t19.3928\t745.1083\t0.2788\t946.6764\t0.77526\t0.7435036\t0.8951\tFalse\n",
      "21\t500\t19.2834\t19.3935\t834.7669\t0.4649\t946.3466\t0.77608955\t0.7430917\t0.9017\tFalse\n",
      "21\t600\t19.289\t19.3947\t792.47\t0.4113\t948.9471\t0.7757648\t0.74493295\t0.9007\tFalse\n",
      "21\t700\t19.2692\t19.4149\t865.5056\t0.3815\t948.5084\t0.7753551\t0.7400028\t0.9083\tFalse\n",
      "21\t800\t19.276\t19.4006\t869.611\t0.2565\t951.1677\t0.77511525\t0.74017435\t0.9274\tFalse\n",
      "21\t900\t19.2801\t19.3918\t895.1946\t0.3299\t947.546\t0.77497864\t0.7390431\t0.9127\tFalse\n",
      "21\t1000\t19.2778\t19.412\t835.5759\t0.3756\t947.9844\t0.7750332\t0.7382722\t0.9299\tFalse\n",
      "21\t1100\t19.2732\t19.3935\t833.2258\t0.425\t949.9972\t0.7748663\t0.73647016\t1.0254\tFalse\n",
      "21\t1200\t19.2913\t19.3959\t800.5564\t0.289\t948.2778\t0.7751775\t0.7377519\t0.9427\tFalse\n",
      "21\t1300\t19.279\t19.4121\t908.5341\t0.3739\t946.1279\t0.77614725\t0.74057305\t0.9219\tFalse\n",
      "21\t1400\t19.2776\t19.3906\t811.5942\t0.3888\t947.5523\t0.77544826\t0.73796713\t0.9183\tFalse\n",
      "21\t1500\t19.2668\t19.3989\t785.7612\t0.3553\t947.4315\t0.7756092\t0.7394424\t0.902\tFalse\n",
      "21\t1600\t19.2641\t19.4061\t793.9857\t0.2381\t948.6519\t0.77544916\t0.744099\t0.8863\tFalse\n",
      "21\t1700\t19.2765\t19.3913\t836.4711\t0.5636\t948.6818\t0.7757431\t0.74503917\t0.8779\tFalse\n",
      "21\t1800\t19.2796\t19.3914\t827.9545\t0.3406\t947.3213\t0.77550113\t0.73939234\t0.9361\tFalse\n",
      "21\t1900\t19.2699\t19.4081\t931.7261\t0.2397\t950.4507\t0.7757245\t0.73968\t0.8973\tFalse\n",
      "21\t2000\t19.276\t19.3931\t852.5051\t0.3332\t945.222\t0.77652335\t0.73902416\t0.9062\tFalse\n",
      "21\t2100\t19.2736\t19.3952\t824.2495\t0.4143\t946.7287\t0.7759072\t0.7395151\t0.9485\tFalse\n",
      "21\t2200\t19.2747\t19.4051\t853.5441\t0.2544\t946.9893\t0.7753998\t0.7370137\t0.9226\tFalse\n",
      "21\t2300\t19.2691\t19.3935\t870.4408\t0.6077\t949.0407\t0.7749491\t0.73800516\t0.9247\tFalse\n",
      "21\t2400\t19.2714\t19.3966\t1023.1415\t0.2431\t951.7001\t0.7741813\t0.73318964\t0.9185\tFalse\n",
      "21\t2500\t19.2827\t19.3976\t937.7344\t0.2927\t950.4915\t0.77496296\t0.7339722\t0.9283\tFalse\n",
      "21\t2600\t19.2755\t19.3969\t808.0987\t0.4496\t947.0344\t0.77507925\t0.7368528\t0.9066\tFalse\n",
      "21\t2700\t19.2725\t19.3981\t973.2178\t0.2438\t948.3496\t0.77571905\t0.7392278\t0.9245\tFalse\n",
      "21\t2800\t19.277\t19.399\t862.0202\t0.527\t951.208\t0.775141\t0.74150217\t0.9317\tFalse\n",
      "21\t2900\t19.282\t19.399\t865.4258\t0.2944\t946.2824\t0.7759302\t0.7414745\t0.8981\tFalse\n",
      "21\t3000\t19.2797\t19.3976\t972.4329\t0.4307\t950.3193\t0.7757805\t0.73400414\t1.1147\tFalse\n",
      "21\t3100\t19.2846\t19.3955\t788.6938\t0.468\t947.2502\t0.7751252\t0.7377406\t0.9144\tFalse\n",
      "21\t3200\t19.2892\t19.3995\t724.656\t0.3294\t950.6492\t0.7752516\t0.738197\t0.9074\tFalse\n",
      "22\t0\t4.5677\t19.3986\t849.38\t0.29\t949.033\t0.77471554\t0.7406011\t0.9094\tFalse\n",
      "22\t100\t19.2699\t19.3933\t864.9246\t0.2267\t946.8303\t0.7761635\t0.74012744\t0.9197\tFalse\n",
      "22\t200\t19.2659\t19.3949\t783.8148\t0.2616\t946.5476\t0.77670944\t0.74635714\t0.8783\tFalse\n",
      "22\t300\t19.2708\t19.3917\t961.6395\t0.2241\t946.6802\t0.7754435\t0.7373878\t0.9095\tFalse\n",
      "22\t400\t19.2881\t19.3971\t810.7339\t0.5556\t946.5823\t0.7760121\t0.7400796\t0.9105\tFalse\n",
      "22\t500\t19.2728\t19.4013\t845.7089\t0.4478\t947.7849\t0.77622813\t0.7407884\t0.9794\tFalse\n",
      "22\t600\t19.2699\t19.3908\t877.631\t0.3106\t946.8254\t0.77509755\t0.7391709\t0.9193\tFalse\n",
      "22\t700\t19.2692\t19.3936\t804.5256\t0.2787\t948.2108\t0.77650946\t0.74286866\t0.8947\tFalse\n",
      "22\t800\t19.2717\t19.3911\t809.7485\t0.3318\t952.2943\t0.7748493\t0.74219173\t0.9331\tFalse\n",
      "22\t900\t19.2711\t19.3951\t863.6654\t0.5213\t950.8653\t0.7756439\t0.7384072\t0.9747\tFalse\n",
      "22\t1000\t19.2775\t19.3951\t823.6288\t0.3218\t952.8541\t0.7754487\t0.732662\t0.9432\tFalse\n",
      "22\t1100\t19.2722\t19.3968\t775.7772\t0.3814\t949.9009\t0.7753102\t0.7375571\t0.9075\tFalse\n",
      "22\t1200\t19.2708\t19.3971\t747.5697\t0.8599\t948.7625\t0.77478623\t0.73284996\t0.9298\tFalse\n",
      "22\t1300\t19.2617\t19.3934\t941.3353\t0.3216\t948.3286\t0.77452606\t0.7401154\t0.9264\tFalse\n",
      "22\t1400\t19.2736\t19.3939\t737.3442\t0.4306\t951.0647\t0.7749896\t0.73633426\t0.9484\tFalse\n",
      "22\t1500\t19.2623\t19.3924\t815.0952\t0.4917\t949.1614\t0.7754222\t0.73792225\t0.9242\tFalse\n",
      "22\t1600\t19.2677\t19.4013\t886.6215\t0.2792\t949.9007\t0.77549803\t0.7433955\t0.9657\tFalse\n"
     ]
    }
   ],
   "source": [
    "# Use the models fit_generator method to train the model\n",
    "print(\"Fitting the model\")\n",
    "arch.fit(\n",
    "    train_dl,\n",
    "    optimizer,\n",
    "    X_valid=X_valid,\n",
    "    y_valid=y_valid,\n",
    "    max_epochs=max_epochs,\n",
    "    validation_iter=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = arch.accessibility.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>Training MNLL</th>\n",
       "      <th>Training Count MSE</th>\n",
       "      <th>Validation MNLL</th>\n",
       "      <th>Validation Profile Correlation</th>\n",
       "      <th>Validation Count Pearson</th>\n",
       "      <th>Validation Count MSE</th>\n",
       "      <th>Saved?</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.517701</td>\n",
       "      <td>19.500207</td>\n",
       "      <td>932.241760</td>\n",
       "      <td>1.544799</td>\n",
       "      <td>1056.473267</td>\n",
       "      <td>0.732217</td>\n",
       "      <td>0.628830</td>\n",
       "      <td>1.216397</td>\n",
       "      <td>True</td>\n",
       "      <td>1056.289156</td>\n",
       "      <td>1154.149911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>19.314644</td>\n",
       "      <td>19.495747</td>\n",
       "      <td>1012.177124</td>\n",
       "      <td>0.810664</td>\n",
       "      <td>1052.048584</td>\n",
       "      <td>0.732858</td>\n",
       "      <td>0.633140</td>\n",
       "      <td>1.231875</td>\n",
       "      <td>True</td>\n",
       "      <td>1077.273419</td>\n",
       "      <td>1150.968151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>19.317626</td>\n",
       "      <td>19.488326</td>\n",
       "      <td>1131.588135</td>\n",
       "      <td>1.736926</td>\n",
       "      <td>1050.762207</td>\n",
       "      <td>0.732823</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>1.216017</td>\n",
       "      <td>True</td>\n",
       "      <td>1271.063270</td>\n",
       "      <td>1148.408392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>19.309565</td>\n",
       "      <td>19.485497</td>\n",
       "      <td>1040.878662</td>\n",
       "      <td>1.462553</td>\n",
       "      <td>1050.021606</td>\n",
       "      <td>0.734956</td>\n",
       "      <td>0.638465</td>\n",
       "      <td>1.206140</td>\n",
       "      <td>True</td>\n",
       "      <td>1158.321651</td>\n",
       "      <td>1146.874613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>19.316967</td>\n",
       "      <td>19.487063</td>\n",
       "      <td>969.075684</td>\n",
       "      <td>1.599156</td>\n",
       "      <td>1053.083252</td>\n",
       "      <td>0.734584</td>\n",
       "      <td>0.634420</td>\n",
       "      <td>1.286828</td>\n",
       "      <td>False</td>\n",
       "      <td>1097.487903</td>\n",
       "      <td>1156.415553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>49</td>\n",
       "      <td>2800</td>\n",
       "      <td>19.244409</td>\n",
       "      <td>19.402450</td>\n",
       "      <td>990.148376</td>\n",
       "      <td>0.286468</td>\n",
       "      <td>948.757568</td>\n",
       "      <td>0.774852</td>\n",
       "      <td>0.731137</td>\n",
       "      <td>0.936274</td>\n",
       "      <td>False</td>\n",
       "      <td>1013.151783</td>\n",
       "      <td>1023.940403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>49</td>\n",
       "      <td>2900</td>\n",
       "      <td>19.246675</td>\n",
       "      <td>19.418544</td>\n",
       "      <td>726.764648</td>\n",
       "      <td>0.377520</td>\n",
       "      <td>952.912842</td>\n",
       "      <td>0.773578</td>\n",
       "      <td>0.730125</td>\n",
       "      <td>0.938989</td>\n",
       "      <td>False</td>\n",
       "      <td>757.079504</td>\n",
       "      <td>1028.313667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>49</td>\n",
       "      <td>3000</td>\n",
       "      <td>19.255188</td>\n",
       "      <td>19.397863</td>\n",
       "      <td>744.717346</td>\n",
       "      <td>0.616022</td>\n",
       "      <td>953.682739</td>\n",
       "      <td>0.773991</td>\n",
       "      <td>0.730778</td>\n",
       "      <td>0.942902</td>\n",
       "      <td>False</td>\n",
       "      <td>794.183931</td>\n",
       "      <td>1029.397801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>49</td>\n",
       "      <td>3100</td>\n",
       "      <td>19.258972</td>\n",
       "      <td>19.398536</td>\n",
       "      <td>776.912598</td>\n",
       "      <td>0.262185</td>\n",
       "      <td>954.717102</td>\n",
       "      <td>0.773742</td>\n",
       "      <td>0.728880</td>\n",
       "      <td>0.953527</td>\n",
       "      <td>False</td>\n",
       "      <td>797.966047</td>\n",
       "      <td>1031.285308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>49</td>\n",
       "      <td>3200</td>\n",
       "      <td>19.250720</td>\n",
       "      <td>19.417841</td>\n",
       "      <td>1013.207153</td>\n",
       "      <td>0.157189</td>\n",
       "      <td>950.850708</td>\n",
       "      <td>0.774313</td>\n",
       "      <td>0.729731</td>\n",
       "      <td>0.949808</td>\n",
       "      <td>False</td>\n",
       "      <td>1025.829427</td>\n",
       "      <td>1027.120314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1617 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Epoch  Iteration  Training Time  Validation Time  Training MNLL  \\\n",
       "33        1          0       5.517701        19.500207     932.241760   \n",
       "34        1        100      19.314644        19.495747    1012.177124   \n",
       "35        1        200      19.317626        19.488326    1131.588135   \n",
       "36        1        300      19.309565        19.485497    1040.878662   \n",
       "37        1        400      19.316967        19.487063     969.075684   \n",
       "...     ...        ...            ...              ...            ...   \n",
       "1645     49       2800      19.244409        19.402450     990.148376   \n",
       "1646     49       2900      19.246675        19.418544     726.764648   \n",
       "1647     49       3000      19.255188        19.397863     744.717346   \n",
       "1648     49       3100      19.258972        19.398536     776.912598   \n",
       "1649     49       3200      19.250720        19.417841    1013.207153   \n",
       "\n",
       "      Training Count MSE  Validation MNLL  Validation Profile Correlation  \\\n",
       "33              1.544799      1056.473267                        0.732217   \n",
       "34              0.810664      1052.048584                        0.732858   \n",
       "35              1.736926      1050.762207                        0.732823   \n",
       "36              1.462553      1050.021606                        0.734956   \n",
       "37              1.599156      1053.083252                        0.734584   \n",
       "...                  ...              ...                             ...   \n",
       "1645            0.286468       948.757568                        0.774852   \n",
       "1646            0.377520       952.912842                        0.773578   \n",
       "1647            0.616022       953.682739                        0.773991   \n",
       "1648            0.262185       954.717102                        0.773742   \n",
       "1649            0.157189       950.850708                        0.774313   \n",
       "\n",
       "      Validation Count Pearson  Validation Count MSE  Saved?  Training Loss  \\\n",
       "33                    0.628830              1.216397    True    1056.289156   \n",
       "34                    0.633140              1.231875    True    1077.273419   \n",
       "35                    0.633143              1.216017    True    1271.063270   \n",
       "36                    0.638465              1.206140    True    1158.321651   \n",
       "37                    0.634420              1.286828   False    1097.487903   \n",
       "...                        ...                   ...     ...            ...   \n",
       "1645                  0.731137              0.936274   False    1013.151783   \n",
       "1646                  0.730125              0.938989   False     757.079504   \n",
       "1647                  0.730778              0.942902   False     794.183931   \n",
       "1648                  0.728880              0.953527   False     797.966047   \n",
       "1649                  0.729731              0.949808   False    1025.829427   \n",
       "\n",
       "      Validation Loss  \n",
       "33        1154.149911  \n",
       "34        1150.968151  \n",
       "35        1148.408392  \n",
       "36        1146.874613  \n",
       "37        1156.415553  \n",
       "...               ...  \n",
       "1645      1023.940403  \n",
       "1646      1028.313667  \n",
       "1647      1029.397801  \n",
       "1648      1031.285308  \n",
       "1649      1027.120314  \n",
       "\n",
       "[1617 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df[log_df[\"Iteration\"].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log dataframe\n",
    "log_df = pd.read_csv(prefix + \".log\", sep=\"\\t\")\n",
    "log_df[\"Training Loss\"] = log_df[\"Training MNLL\"] + alpha*log_df[\"Training Count MSE\"]\n",
    "log_df[\"Validation Loss\"] = log_df[\"Validation MNLL\"] + alpha*log_df[\"Validation Count MSE\"]\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=log_df, x=\"Iteration\", y=\"Validation Loss\", label=\"Validation Loss\")\n",
    "    sns.lineplot(data=log_df, x=\"Iteration\", y=\"Training Loss\", label=\"Training Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Total Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(prefix + \"_loss.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating the model on test data ---\n",
      "Loading best model from file\n"
     ]
    }
   ],
   "source": [
    "#-------------- Test data evaluation the model --------------#\n",
    "print(\"--- Evaluating the model on test data ---\")\n",
    "batch_size = params[\"evaluation\"][\"batch_size\"]\n",
    "\n",
    "# Load the model\n",
    "print(\"Loading best model from file\")\n",
    "arch = torch.load(prefix + \".torch\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# test seqs: 107270\n",
      "\n",
      "Predicting on test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [02:00<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test SeqData to /cellar/users/aklie/projects/ML4GLand/tutorials/bulk_atac_basepair/eugene/chrombpnet/fold_0/0.5/K562_ATAC-seq_chrombpnet_fold_0.test.seqdata\n"
     ]
    }
   ],
   "source": [
    "# Test data        \n",
    "test_idx = np.where(sdata[fold] == \"test\")[0]\n",
    "test_data = sdata.isel(_sequence=test_idx)\n",
    "print(f\"# test seqs: {test_data.dims['_sequence']}\\n\")\n",
    "\n",
    "# Get predictions\n",
    "test_out = os.path.join(path_out, f\"{name}.test.seqdata\")\n",
    "generate = True\n",
    "if os.path.exists(test_out):\n",
    "    if not overwrite:\n",
    "        print(\"Test SeqData already exists. Set overwrite to true in config to overwrite.\")\n",
    "        generate = False\n",
    "        print(f\"Loaded test SeqData from {test_out}\")\n",
    "        test_data = sd.open_zarr(test_out)\n",
    "if generate:\n",
    "    print(\"Predicting on test data\")\n",
    "    true_counts = torch.tensor(test_data[cov_var].values[..., counts_start:counts_start + target_length].sum(axis=-1), dtype=torch.float32)\n",
    "    test_data[\"log_counts\"] = xr.DataArray(torch.log(true_counts+1).numpy(), dims=[\"_sequence\", \"cov_sample\"])\n",
    "    X_test = torch.tensor(sp.ohe(test_data[seq_var].values[:, seqs_start:seqs_start + seq_length], alphabet=sp.DNA).transpose(0, 2, 1), dtype=torch.float32)\n",
    "    y_profiles, y_counts = predict(arch, X_test, batch_size=batch_size, device=\"cuda\", verbose=True)\n",
    "    test_data[f\"{fold}_log_counts_pred\"] = xr.DataArray(y_counts.cpu().numpy(), dims=[\"_sequence\", \"cov_sample\"])\n",
    "    test_data[f\"{fold}_profile_pred\"] = xr.DataArray(y_profiles.cpu().numpy(), dims=[\"_sequence\", \"cov_sample\", \"_target_length\"])     \n",
    "    sd.to_zarr(test_data, test_out, mode=\"w\")        \n",
    "    print(f\"Saved test SeqData to {test_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating scatter plots\n"
     ]
    }
   ],
   "source": [
    "# Scatter plots\n",
    "print(\"Creating scatter plots\")\n",
    "type_msk = (test_data[\"type\"] == \"loci\")\n",
    "loci_counts = test_data[\"log_counts\"].values[type_msk]\n",
    "loci_counts_pred = test_data[f\"{fold}_log_counts_pred\"].values[type_msk]\n",
    "scatter(\n",
    "    loci_counts,\n",
    "    loci_counts_pred,\n",
    "    figsize=(4, 4),\n",
    "    xlabel=\"Observed Log Counts\",\n",
    "    ylabel=\"Predicted Log Counts\",\n",
    "    save=prefix + \"_loci_counts_scatter.png\",\n",
    "    density=False,\n",
    "    add_reference_line=False,\n",
    "    return_axes=False,\n",
    ")\n",
    "neg_counts = test_data[\"log_counts\"].values[~type_msk]\n",
    "neg_counts_pred = test_data[f\"{fold}_log_counts_pred\"].values[~type_msk]\n",
    "scatter(\n",
    "    neg_counts,\n",
    "    neg_counts_pred,\n",
    "    figsize=(4, 4),\n",
    "    xlabel=\"Observed Log Counts\",\n",
    "    ylabel=\"Predicted Log Counts\",\n",
    "    save=prefix + \"_neg_counts_scatter.png\",\n",
    "    density=False,\n",
    "    add_reference_line=False,\n",
    "    return_axes=False,\n",
    ")\n",
    "counts = test_data[\"log_counts\"].values\n",
    "counts_pred = test_data[f\"{fold}_log_counts_pred\"].values\n",
    "scatter(\n",
    "    counts,\n",
    "    counts_pred,\n",
    "    figsize=(4, 4),\n",
    "    xlabel=\"Observed Log Counts\",\n",
    "    ylabel=\"Predicted Log Counts\",\n",
    "    save=prefix + \"_counts_scatter.png\",\n",
    "    density=False,\n",
    "    add_reference_line=False,\n",
    "    return_axes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tangermeme.predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 117/420 [00:28<01:12,  4.16it/s]"
     ]
    }
   ],
   "source": [
    "y_accessibility_profiles, y_accessibility_counts = predict(arch.accessibility, X_test, batch_size=batch_size, device=\"cuda\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- Prediction bigwigs --------------#\n",
    "pred_logits_wo_bias, pred_logcts_wo_bias = model_chrombpnet_nb.predict([seqs],\n",
    "                                          batch_size = args.batch_size,\n",
    "                                          verbose=True)\n",
    "\n",
    "pred_logits_wo_bias = np.squeeze(pred_logits_wo_bias)\n",
    "\n",
    "\n",
    "bigwig_helper.write_bigwig(softmax(pred_logits_wo_bias) * (np.expand_dims(np.exp(pred_logcts_wo_bias)[:,0],axis=1)), \n",
    "                    regions, \n",
    "                    gs, \n",
    "                    args.output_prefix + \"_chrombpnet_nobias.bw\", \n",
    "                    outstats_file=args.output_prefix_stats, \n",
    "                    debug_chr=args.debug_chr, \n",
    "                    use_tqdm=args.tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bigwig(data, regions, gs, bw_out, debug_chr=None, use_tqdm=False, outstats_file=None):\n",
    "    # regions may overlap but as we go in sorted order, at a given position,\n",
    "    # we will pick the value from the interval whose summit is closest to \n",
    "    # current position\n",
    "    \n",
    "    chr_to_idx = {}\n",
    "    for i,x in enumerate(gs):\n",
    "        chr_to_idx[x[0]] = i\n",
    "\n",
    "    bw = pyBigWig.open(bw_out, 'w')\n",
    "    bw.addHeader(gs)\n",
    "    \n",
    "    # regions may not be sorted, so get their sorted order\n",
    "    order_of_regs = sorted(range(len(regions)), key=lambda x:(chr_to_idx[regions[x][0]], regions[x][1]))\n",
    "\n",
    "    all_entries = []\n",
    "    cur_chr = \"\"\n",
    "    cur_end = 0\n",
    "\n",
    "    iterator = range(len(order_of_regs))\n",
    "    if use_tqdm:\n",
    "        from tqdm import tqdm\n",
    "        iterator = tqdm(iterator)\n",
    "\n",
    "    for itr in iterator:\n",
    "        # subset to chromosome (debugging)\n",
    "        if debug_chr and regions[i][0]!=debug_chr:\n",
    "            continue\n",
    "\n",
    "        i = order_of_regs[itr]\n",
    "        i_chr, i_start, i_end, i_mid = regions[i]\n",
    "    \n",
    "        if i_chr != cur_chr: \n",
    "            cur_chr = i_chr\n",
    "            cur_end = 0\n",
    "    \n",
    "        # bring current end to at least start of current region\n",
    "        if cur_end < i_start:\n",
    "            cur_end = i_start\n",
    "    \n",
    "        assert(regions[i][2]>=cur_end)\n",
    "    \n",
    "        # figure out where to stop for this region, get next region\n",
    "        # which may partially overlap with this one\n",
    "        next_end = i_end\n",
    "    \n",
    "        if itr+1 != len(order_of_regs):\n",
    "            n = order_of_regs[itr+1]\n",
    "            next_chr, next_start, _, next_mid = regions[n]\n",
    "       \n",
    "            if next_chr == i_chr and next_start < i_end:\n",
    "                # if next region overlaps with this, end between their midpoints\n",
    "                next_end = (i_mid+next_mid)//2\n",
    "       \n",
    "        vals = data[i][cur_end - i_start:next_end - i_start]\n",
    "\n",
    "        bw.addEntries([i_chr]*(next_end-cur_end), \n",
    "                       list(range(cur_end,next_end)), \n",
    "                       ends = list(range(cur_end+1, next_end+1)), \n",
    "                       values=[float(x) for x in vals])\n",
    "    \n",
    "        all_entries.append(vals)\n",
    "        \n",
    "        cur_end = next_end\n",
    "\n",
    "    bw.close()\n",
    "\n",
    "    all_entries = np.hstack(all_entries)\n",
    "    if outstats_file != None:\n",
    "        with open(outstats_file, 'w') as f:\n",
    "            f.write(\"Min\\t{:.6f}\\n\".format(np.min(all_entries)))\n",
    "            f.write(\".1%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.001)))\n",
    "            f.write(\"1%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.01)))\n",
    "            f.write(\"50%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.5)))\n",
    "            f.write(\"99%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.99)))\n",
    "            f.write(\"99.9%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.999)))\n",
    "            f.write(\"99.95%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.9995)))\n",
    "            f.write(\"99.99%\\t{:.6f}\\n\".format(np.quantile(all_entries, 0.9999)))\n",
    "            f.write(\"Max\\t{:.6f}\\n\".format(np.max(all_entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "\n",
    "            \n",
    "\n",
    "    #-------------- Attribution --------------#\n",
    "    if \"attribution\" in params:\n",
    "        print(\"--- Computing attribution on 30k subsample ---\")\n",
    "        batch_size = params[\"attribution\"][\"batch_size\"]\n",
    "        subsample = params[\"attribution\"][\"subsample\"]\n",
    "        n_shuffles = params[\"attribution\"][\"n_shuffles\"]\n",
    "        \n",
    "        # Write test SeqData\n",
    "        attr_out = os.path.join(path_out, f\"{name}.sub.attr.seqdata\")\n",
    "        generate = True\n",
    "        if os.path.exists(attr_out):\n",
    "            if not overwrite:\n",
    "                print(\"Subsampled SeqData already exists. Set overwrite to true in config to overwrite.\")\n",
    "                generate = False\n",
    "                print(f\"Loading attribution subsample from {attr_out}\")\n",
    "                test_loci = sd.open_zarr(attr_out)\n",
    "                X = test_loci[\"X_ohe\"].values\n",
    "                X_attr_counts = test_loci[\"X_attr_counts\"].values\n",
    "                X_attr_profile = test_loci[\"X_attr_profile\"].values\n",
    "        \n",
    "        if generate:\n",
    "            # Subsample loci\n",
    "            print(f\"Targeting {subsample} loci for attributions\")\n",
    "            test_loci_idx = np.where(test_data[\"type\"] == \"loci\")[0]\n",
    "            test_loci = test_data.isel(_sequence=test_loci_idx)\n",
    "            if test_loci.dims[\"_sequence\"] > subsample:\n",
    "                random_idx = np.random.choice(test_loci.dims[\"_sequence\"], subsample, replace=False)\n",
    "                test_loci = test_loci.isel(_sequence=sorted(random_idx))\n",
    "            X = torch.tensor(sp.ohe(test_loci[\"seq\"].values[:, seqs_start:seqs_start + seq_length], alphabet=sp.DNA).transpose(0, 2, 1), dtype=torch.float32)\n",
    "            n_msk = X.sum(dim=(1, 2)) == X.shape[-1]\n",
    "            X = X[n_msk]\n",
    "            n_idx = np.where(n_msk)[0]\n",
    "            test_loci = test_loci.isel(_sequence=n_idx)\n",
    "            print(f\"Subsampled {subsample} loci with no non-alphabet characters\")\n",
    "        \n",
    "            # Get count attributions\n",
    "            print(\"Computing count attributions\")\n",
    "            count_wrapper = CountWrapper(ControlWrapper(arch)).cuda().eval()\n",
    "            dtype = torch.float64\n",
    "            X_attr_counts = deep_lift_shap(\n",
    "                count_wrapper.type(dtype), \n",
    "                X.type(dtype),\n",
    "                hypothetical=True,\n",
    "                n_shuffles=n_shuffles,\n",
    "                batch_size=batch_size,\n",
    "                verbose=True,\n",
    "                warning_threshold=1e-4\n",
    "            )\n",
    "\n",
    "            # Get profile attributions\n",
    "            print(\"Computing profile attributions\")\n",
    "            profile_wrapper = ProfileWrapper(ControlWrapper(arch)).cuda().eval()\n",
    "            X_attr_profile = deep_lift_shap(\n",
    "                profile_wrapper.type(dtype), \n",
    "                X.type(dtype),\n",
    "                hypothetical=True,\n",
    "                additional_nonlinear_ops={_ProfileLogitScaling: _nonlinear}, \n",
    "                n_shuffles=n_shuffles,\n",
    "                batch_size=batch_size,\n",
    "                verbose=True,\n",
    "                warning_threshold=1e-4\n",
    "            )\n",
    "            \n",
    "            # Save attributions\n",
    "            X = X.cpu().numpy()\n",
    "            X_attr_counts = X_attr_counts.cpu().numpy()\n",
    "            X_attr_profile = X_attr_profile.cpu().numpy()\n",
    "            test_loci[\"X_ohe\"] = xr.DataArray(X, dims=[\"_sequence\", \"_alphabet\", \"_trimmed_length\"])\n",
    "            test_loci[\"X_attr_counts\"] = xr.DataArray(X_attr_counts, dims=[\"_sequence\", \"_alphabet\", \"_trimmed_length\"])\n",
    "            test_loci[\"X_attr_profile\"] = xr.DataArray(X_attr_profile, dims=[\"_sequence\", \"_alphabet\", \"_trimmed_length\"])\n",
    "            sd.to_zarr(test_loci, attr_out, mode=\"w\")\n",
    "            print(f\"Saved attribution subset SeqData to {attr_out}\")\n",
    "                \n",
    "\n",
    "    if \"modisco\" in params:\n",
    "        print(\"--- Running TFMoDISco ---\")\n",
    "        n_seqlets = params[\"modisco\"][\"n_seqlets\"]\n",
    "        window = params[\"modisco\"][\"window\"]\n",
    "        motif_db = params[\"modisco\"][\"motif_db\"]\n",
    "        \n",
    "        # Get sequences for modisco\n",
    "        center = X.shape[2] // 2\n",
    "        start, end = calculate_window_offsets(center, window)\n",
    "        sequences = X[:, :, start:end].transpose(0, 2, 1).astype('float32')\n",
    "\n",
    "        # Counts modisco\n",
    "        modisco_out = os.path.join(path_out, f\"{name}_modisco_counts.h5\")\n",
    "        generate = True\n",
    "        if os.path.exists(modisco_out):\n",
    "            if not overwrite:\n",
    "                print(\"TFMoDISco output already exists. Set overwrite to true in config to overwrite.\")\n",
    "                generate = False\n",
    "                print(f\"Loading TFMoDISco results from {modisco_out}\")\n",
    "        if generate:\n",
    "            print(\"Using count attributions for TFMoDISco\")\n",
    "            attributions = X_attr_counts[:, :, start:end].transpose(0, 2, 1).astype('float32')\n",
    "            pos_patterns, neg_patterns = modiscolite.tfmodisco.TFMoDISco(\n",
    "                hypothetical_contribs=attributions, \n",
    "                one_hot=sequences,\n",
    "                max_seqlets_per_metacluster=n_seqlets,\n",
    "                sliding_window_size=20,\n",
    "                flank_size=5,\n",
    "                target_seqlet_fdr=0.05,\n",
    "                n_leiden_runs=2,\n",
    "                verbose=True\n",
    "            )\n",
    "            modiscolite.io.save_hdf5(prefix + \"_modisco_counts.h5\", pos_patterns, neg_patterns, window)\n",
    "            print(f\"Saved count attributions TFMoDISco results to {prefix}_modisco_counts.h5\")\n",
    "        \n",
    "        # Profile modisco\n",
    "        modisco_out = os.path.join(path_out, f\"{name}_modisco_profile.h5\")\n",
    "        generate = True\n",
    "        if os.path.exists(modisco_out):\n",
    "            if not overwrite:\n",
    "                print(\"TFMoDISco output already exists. Set overwrite to true in config to overwrite.\")\n",
    "                generate = False\n",
    "                print(f\"Loading TFMoDISco results from {modisco_out}\")\n",
    "        if generate:\n",
    "            print(\"Using profile attributions for TFMoDISco\")\n",
    "            attributions = X_attr_profile[:, :, start:end].transpose(0, 2, 1).astype('float32')\n",
    "            pos_patterns, neg_patterns = modiscolite.tfmodisco.TFMoDISco(\n",
    "                hypothetical_contribs=attributions, \n",
    "                one_hot=sequences,\n",
    "                max_seqlets_per_metacluster=n_seqlets,\n",
    "                sliding_window_size=20,\n",
    "                flank_size=5,\n",
    "                target_seqlet_fdr=0.05,\n",
    "                n_leiden_runs=2,\n",
    "                verbose=True\n",
    "            )\n",
    "            modiscolite.io.save_hdf5(prefix + \"_modisco_profile.h5\", pos_patterns, neg_patterns, window)\n",
    "            print(f\"Saved profile attributions TFMoDISco results to {prefix}_modisco_profile.h5\")\n",
    "    \n",
    "        print(\"--- Creating TFMoDISco reports ---\")\n",
    "        report_out = os.path.join(path_out, f\"{name}_modisco_counts_report\")\n",
    "        generate = True\n",
    "        if os.path.exists(report_out):\n",
    "            if not overwrite:\n",
    "                print(\"Counts TFMoDISco report already exists. Set overwrite to true in config to overwrite.\")\n",
    "                generate = False\n",
    "        if generate:\n",
    "            modiscolite.report.report_motifs(\n",
    "                modisco_h5py=prefix + \"_modisco_counts.h5\",\n",
    "                output_dir=prefix + \"_modisco_counts_report/\",\n",
    "                img_path_suffix=prefix + \"_modisco_counts_report/\",\n",
    "                meme_motif_db=motif_db,\n",
    "                is_writing_tomtom_matrix=False,\n",
    "                top_n_matches=3\n",
    "            )\n",
    "            print(f\"Saved counts TFMoDISco report to {prefix}_modisco_counts_report\")\n",
    "\n",
    "        report_out = os.path.join(path_out, f\"{name}_modisco_profile_report\")\n",
    "        generate = True\n",
    "        if os.path.exists(report_out):\n",
    "            if not overwrite:\n",
    "                print(\"Profile TFMoDISco report already exists. Set overwrite to true in config to overwrite.\")\n",
    "                generate = False\n",
    "        if generate:\n",
    "            modiscolite.report.report_motifs(\n",
    "                modisco_h5py=prefix + \"_modisco_profile.h5\",\n",
    "                output_dir=prefix + \"_modisco_profile_report/\",\n",
    "                img_path_suffix=prefix + \"_modisco_profile_report/\",\n",
    "                meme_motif_db=motif_db,\n",
    "                is_writing_tomtom_matrix=False,\n",
    "                top_n_matches=3\n",
    "            )\n",
    "            print(f\"Saved profile TFMoDISco report to {prefix}_modisco_profile_report\")\n",
    "\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 eugene_tools",
   "language": "python",
   "name": "eugene_tools"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
